{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6ea9ad9f-568e-4504-9dfe-4c1aab69d565",
   "metadata": {},
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5bae2266-99b8-4cc6-91bf-e93f677ced7b",
   "metadata": {},
   "source": [
    "conda install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66a53507-ae8e-491d-af72-2605342fcfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf8af696-26e3-43a6-858b-af6745bae15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('subword_train.csv')\n",
    "df_test = pd.read_csv('subword_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aba4ad36-32b8-44e5-9513-2f86c02d7a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24291766-7c73-441a-a605-898094311254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19b8a016-b259-4f37-bab6-43c3f14e7b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "7608  Two giant cranes holding a bridge collapse int...       1  \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
       "7611  Police investigating after an e-bike collided ...       1  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef8c91fc-3372-4883-82b5-e46b0a8b84b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2680445f-7938-4c1c-abdd-13dd53092aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e74de5f3-ee88-4384-8bfa-c882373fa1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentences):\n",
    "    sentences = sentences.lower() # 소문자 처리\n",
    "    sentences = sentences.translate(str.maketrans(' ', ' ', punctuations)) # 구두점 제거\n",
    "    sentences = word_tokenize(sentences)\n",
    "    sentences = [s for s in sentences if s not in stops] # 불용어 제거\n",
    "    return ' '.join(sentences) # 문자열로 합하여 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d99aba1d-ac74-48e7-be2b-2b3cd1bc3704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature(keyword, location, text):\n",
    "    if pd.isnull(keyword):\n",
    "        keyword = ''\n",
    "    if pd.isnull(location):\n",
    "        location = ''\n",
    "\n",
    "    try:\n",
    "        return keyword + ' ' + location + ' ' + text\n",
    "    except:\n",
    "        print('keyword :', keyword)\n",
    "        print('location :', location)\n",
    "        print('text : ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f87d5f7d-914e-48b4-a699-b482d283ad85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 처리\n",
    "# 특수문자 제거\n",
    "punctuations = string.punctuation\n",
    "punctuations = punctuations.translate({ord('@'): None}) # 구두점 목록에서 @를 제거\n",
    "punctuations = punctuations.translate({ord('#'): None}) # 구두점 목록에서 #을 제거\n",
    "stops = stopwords.words('english') \n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "130a161a-f42c-449e-b185-0704e6fe7a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터에 적용\n",
    "feature = [preprocess(make_feature(k, l, t)) for k, l, t in zip(df_train['keyword'], df_train['location'], df_train['text'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bd30172-be80-40df-98ae-346c12c5d256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deeds reason # earthquake may allah forgive us'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02b320d5-ded8-42d4-9aa4-310ed5df5ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'got sent photo ruby # alaska smoke # wildfires pours school'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c26ce0c-33b6-4025-ab45-f74e6566e3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature = [preprocess(make_feature(k, l, t)) for k, l, t in zip(df_test['keyword'], df_test['location'], df_test['text'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01195c8b-5af7-4040-b0ff-c4fa7bb23a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happened terrible car crash'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8c4a325-cf49-4799-b80c-34d212b171b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('subword_input.txt', 'w', encoding='utf-8') as f:\n",
    "    for word in feature:\n",
    "        f.write(word)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3e9b70ba-561f-4b00-b961-9401f99b2911",
   "metadata": {},
   "source": [
    "pip install tokenizers"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dc65e88a-d286-4ca2-9eed-56002f902bfe",
   "metadata": {},
   "source": [
    "conda install tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5954e4ae-ce59-405f-8686-527cfff86e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import BertWordPieceTokenizer\n",
    "\n",
    "tokenizer = BertWordPieceTokenizer(lowercase=True, strip_accents=True)\n",
    "\n",
    "data_file = 'subword_input.txt'\n",
    "vocab_size = 30000\n",
    "limit_alphabet = 6000\n",
    "min_frequency = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "051bbe28-124d-475d-9498-34a7a7285e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer.train(files=data_file, vocab_size=vocab_size, limit_alphabet=limit_alphabet, min_frequency=min_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfd59f06-b884-4dd6-9428-bfee66c65a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de', '##eds', 'reason', '#', 'earthquake', 'may', 'allah', 'forg', '##ive', 'us']\n"
     ]
    }
   ],
   "source": [
    "# 트윗의 텍스트(키워드, 위치) target : 실제 재난에 관한 내용인지 확인\n",
    "X_tokens = [tokenizer.encode(tweet).tokens for tweet in feature]\n",
    "print(X_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b038929d-1c3c-4c09-916b-9d4c7d607f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[198, 704, 3149, 5, 1540, 533, 4908, 4931, 279, 208]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ids = [tokenizer.encode(tweet).ids for tweet in feature]\n",
    "X_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e029a080-92b2-47d2-82d8-3187da1f342e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(s) for s in X_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f7fa8cc-1b75-45be-a36c-d98fd007a205",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tokens = [tokenizer.encode(tweet).tokens for tweet in test_feature]\n",
    "X_test_ids = [tokenizer.encode(tweet).ids for tweet in test_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13dd2e4c-daf8-4d1f-98c7-c463e2425eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4940"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.token_to_id('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4ec6b25-d7d7-45ec-b332-f2fe2b0db7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'httptco'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.id_to_token(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8284964c-1dc3-4f4a-aecf-2e4c09bc5f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de\n",
      "d\n",
      "e\n",
      "##eds\n",
      "#\n",
      "#\n",
      "e\n",
      "d\n",
      "s\n",
      "reason\n",
      "r\n",
      "e\n",
      "a\n",
      "s\n",
      "o\n",
      "n\n",
      "#\n",
      "#\n",
      "earthquake\n",
      "e\n",
      "a\n",
      "r\n",
      "t\n",
      "h\n",
      "q\n",
      "u\n",
      "a\n",
      "k\n",
      "e\n",
      "may\n",
      "m\n",
      "a\n",
      "y\n",
      "allah\n",
      "a\n",
      "l\n",
      "l\n",
      "a\n",
      "h\n",
      "forg\n",
      "f\n",
      "o\n",
      "r\n",
      "g\n",
      "##ive\n",
      "#\n",
      "#\n",
      "i\n",
      "v\n",
      "e\n",
      "us\n",
      "u\n",
      "s\n"
     ]
    }
   ],
   "source": [
    "word_to_index = dict()\n",
    "\n",
    "for sent in X_tokens[0]:\n",
    "    print(sent)\n",
    "    for w in sent:\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a85e42f-f05d-4071-944d-a62f5726f0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = dict()\n",
    "\n",
    "for sent in X_tokens[:10]:\n",
    "    for w in sent:\n",
    "        if w not in word_to_index:\n",
    "            word_to_index[w] = tokenizer.token_to_id(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8aaebc96-cec5-4ef1-8d11-e7d714e5a955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'de': 198, '##eds': 704, 'reason': 3149, '#': 5, 'earthquake': 1540, 'may': 533, 'allah': 4908, 'forg': 4931, '##ive': 279, 'us': 208, 'forest': 1143, 'fire': 318, 'near': 681, 'la': 944, 'ron': 5438, '##ge': 376, 'sa': 458, '##s': 63, '##k': 77, 'canada': 820, 'residents': 6357, 'asked': 5289, 'shelter': 7137, 'place': 2537, 'not': 1085, '##ified': 2849, 'officers': 5694, 'evacuation': 1490, 'orders': 4746, 'expected': 3820, '13': 2654, '##000': 1120, 'people': 435, 'rece': 7587, 'wildfires': 4942, 'california': 430, 'got': 584, 'sent': 2999, 'photo': 1664, 'rub': 1697, '##y': 79, 'alaska': 4733, 'smoke': 1512, 'po': 1061, '##urs': 1651, 'school': 1054, 'rocky': 3541, '##fire': 298, 'update': 1890, 'hwy': 4772, '20': 489, 'closed': 3180, 'direction': 2794, 'due': 2235, 'lake': 2582, 'county': 1191, 'ca': 301, 'flood': 486, 'disaster': 511, 'heavy': 2975, 'rain': 796, 'causes': 4205, 'flash': 2773, 'flooding': 1468, 'streets': 5293, 'man': 319, '##ito': 4877, '##u': 66, 'colorado': 1520, 'springs': 4971, 'areas': 5298, 'im': 249, 'top': 1186, 'hill': 2237, 'see': 548, 'wood': 3598, 'theres': 1558, 'emergency': 508, 'happening': 4421, 'building': 2283, 'across': 3081, 'street': 2343, 'afraid': 7830, 'tornado': 1901, 'coming': 1432, 'area': 1332}\n"
     ]
    }
   ],
   "source": [
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6352b793-858c-40d5-8267-69e7368039ff",
   "metadata": {},
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8161297c-c29e-4a0e-88c0-b03dfdfebc40",
   "metadata": {},
   "source": [
    "pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "raw",
   "id": "26438892-dead-4ccc-9682-56d61d1f5ccd",
   "metadata": {},
   "source": [
    "pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "raw",
   "id": "18157079-78f6-42ad-85c3-f7e6a6c98bb1",
   "metadata": {},
   "source": [
    "conda install -c conda-forge flatbuffers"
   ]
  },
  {
   "cell_type": "raw",
   "id": "57cd6691-93ed-433d-97a2-514a8ecf4a3f",
   "metadata": {},
   "source": [
    "conda install -c conda-forge python-flatbuffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ddaffe4-be57-4a81-9d66-3225110152b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a9de32ce-64b1-4ce8-9ba7-ddb5ce47673e",
   "metadata": {},
   "source": [
    "conda list"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0522ef81-2165-47d6-998d-f595f55d9157",
   "metadata": {},
   "source": [
    "pip show keras tensorflow"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d50e6f21-15d5-4d1e-b812-edef49e3f5d9",
   "metadata": {},
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8055a75b-34b7-4072-aa6e-8521d893a8b8",
   "metadata": {},
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d5b8eb79-51a6-429c-81d8-d5b4795c99f9",
   "metadata": {},
   "source": [
    "conda install keras"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5d0f7fe9-12bc-4d97-be1c-52c1a39243f8",
   "metadata": {},
   "source": [
    "pip install flatbuffers"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5279f261-43d8-42ce-bcb5-b71e1a76e3f3",
   "metadata": {},
   "source": [
    "conda install flatbuffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6fe883d-df9b-430a-807b-69f557efb5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68785171-cf92-40b6-ab8f-e2252bc33094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8233"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = tokenizer.get_vocab_size()\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e4c0d2c-3bbf-4352-8a46-228b7edf50a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_padded = pad_sequences(X_ids, maxlen=60, padding='post', value=vocab_size)\n",
    "X_test_padded = pad_sequences(X_test_ids, maxlen=60, padding='post', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f11c5f7-f442-4bf5-9d1c-2d5356dc9ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 198,  704, 3149,    5, 1540,  533, 4908, 4931,  279,  208, 8233,\n",
       "        8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233,\n",
       "        8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233,\n",
       "        8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233,\n",
       "        8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233,\n",
       "        8233, 8233, 8233, 8233, 8233],\n",
       "       [1143,  318,  681,  944, 5438,  376,  458,   63,   77,  820, 8233,\n",
       "        8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233,\n",
       "        8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233,\n",
       "        8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233,\n",
       "        8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233,\n",
       "        8233, 8233, 8233, 8233, 8233],\n",
       "       [6357, 5289, 7137, 2537, 1085, 2849, 5694, 1490, 7137, 2537, 4746,\n",
       "        3820, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233,\n",
       "        8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233,\n",
       "        8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233,\n",
       "        8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233, 8233,\n",
       "        8233, 8233, 8233, 8233, 8233]], dtype=int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_padded[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6a67e6c-d724-467c-b53b-fdedcfda483d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7613, 60), (3263, 60))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_padded.shape, X_test_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "075bf093-c9c6-4221-bd65-b0a2f7fa9aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4c1a4ff3-810e-48c6-9919-628c958ec029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     1\n",
      "1     1\n",
      "2     1\n",
      "3     1\n",
      "4     1\n",
      "     ..\n",
      "95    1\n",
      "96    0\n",
      "97    1\n",
      "98    0\n",
      "99    1\n",
      "Name: target, Length: 100, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d078deb5-f836-4455-94c0-eed2e85949f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8234"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = tokenizer.get_vocab_size()+1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2b7ae6d-c2c2-486b-ba6d-6d76017fb764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Embedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "08d34b07-6486-4ff8-b3c9-ac086c57bd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 64)          526976    \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 64)                24960     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 552,001\n",
      "Trainable params: 552,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 20:12:42.587518: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-11 20:12:42.588384: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-11 20:12:42.588940: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
    "\n",
    "embedding_dim = 64\n",
    "hidden_unit = 64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(GRU(hidden_unit))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "266cc83d-6954-4734-b6c0-e56a122a66b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor = 'val_loss', mode='min', verbose=1, patience=3)\n",
    "mc = ModelCheckpoint('best_model.keras', monitor = 'val_acc', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "254af07d-2ffe-454c-872c-3d119786e072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 20:12:42.655416: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-07-11 20:12:42.791456: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-11 20:12:42.792533: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-11 20:12:42.793170: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-07-11 20:12:43.100509: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-11 20:12:43.101664: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-11 20:12:43.102315: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/108 [============================>.] - ETA: 0s - loss: 0.6831 - acc: 0.5740\n",
      "Epoch 1: val_acc improved from -inf to 0.53412, saving model to best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 20:12:46.658304: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-11 20:12:46.659100: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-11 20:12:46.659634: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 4s 30ms/step - loss: 0.6829 - acc: 0.5744 - val_loss: 0.6937 - val_acc: 0.5341\n",
      "Epoch 2/15\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.6827 - acc: 0.5743\n",
      "Epoch 2: val_acc did not improve from 0.53412\n",
      "108/108 [==============================] - 3s 28ms/step - loss: 0.6827 - acc: 0.5744 - val_loss: 0.6968 - val_acc: 0.5341\n",
      "Epoch 3/15\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.6826 - acc: 0.5743\n",
      "Epoch 3: val_acc did not improve from 0.53412\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.6826 - acc: 0.5744 - val_loss: 0.6959 - val_acc: 0.5341\n",
      "Epoch 4/15\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.6827 - acc: 0.5743\n",
      "Epoch 4: val_acc did not improve from 0.53412\n",
      "108/108 [==============================] - 3s 29ms/step - loss: 0.6827 - acc: 0.5744 - val_loss: 0.6998 - val_acc: 0.5341\n",
      "Epoch 4: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_padded, y, epochs=15, callbacks=[es, mc], batch_size=64, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58977b6b-cd82-4f1b-9e2c-9a77c02139c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238/238 [==============================] - 1s 5ms/step - loss: 0.6851 - acc: 0.5703\n",
      "train acc :  0.5703402161598206\n"
     ]
    }
   ],
   "source": [
    "print('train acc : ', model.evaluate(X_padded, y)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eabc3ecf-6431-489d-8413-5dc8107acd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5cfc494b-63b9-4bd6-ba7f-526f112984a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 20:12:57.423954: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-11 20:12:57.424761: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-11 20:12:57.425332: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-07-11 20:12:57.494914: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2024-07-11 20:12:57.516115: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-11 20:12:57.516677: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-11 20:12:57.517193: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(vocab_size, embedding_dim))\n",
    "model2.add(Bidirectional(LSTM(hidden_unit)))\n",
    "model2.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05461443-31c4-4d7f-b9be-003fe99a3ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7a31875a-a4b8-4416-8043-778277db06d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 20:12:57.660901: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-11 20:12:57.661932: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-11 20:12:57.662537: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-07-11 20:12:57.735118: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2024-07-11 20:12:57.757775: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-11 20:12:57.758463: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-11 20:12:57.759043: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-07-11 20:12:57.999001: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2024-07-11 20:12:58.272303: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-11 20:12:58.273339: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-11 20:12:58.274001: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-07-11 20:12:58.346185: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2024-07-11 20:12:58.368618: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-11 20:12:58.369229: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-11 20:12:58.369798: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-07-11 20:12:58.610657: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/108 [============================>.] - ETA: 0s - loss: 0.5805 - acc: 0.6936"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 20:13:02.810760: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-11 20:13:02.811796: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-11 20:13:02.812598: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-07-11 20:13:02.892548: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2024-07-11 20:13:02.913914: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-11 20:13:02.914499: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-11 20:13:02.915024: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_acc improved from 0.53412 to 0.68766, saving model to best_model.keras\n",
      "108/108 [==============================] - 6s 38ms/step - loss: 0.5803 - acc: 0.6938 - val_loss: 0.6922 - val_acc: 0.6877\n",
      "Epoch 2/15\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.3681 - acc: 0.8430\n",
      "Epoch 2: val_acc improved from 0.68766 to 0.78346, saving model to best_model.keras\n",
      "108/108 [==============================] - 5s 49ms/step - loss: 0.3680 - acc: 0.8431 - val_loss: 0.4753 - val_acc: 0.7835\n",
      "Epoch 3/15\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.2924 - acc: 0.8838\n",
      "Epoch 3: val_acc did not improve from 0.78346\n",
      "108/108 [==============================] - 6s 53ms/step - loss: 0.2924 - acc: 0.8838 - val_loss: 0.5506 - val_acc: 0.7270\n",
      "Epoch 4/15\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.2338 - acc: 0.9108\n",
      "Epoch 4: val_acc did not improve from 0.78346\n",
      "108/108 [==============================] - 6s 53ms/step - loss: 0.2338 - acc: 0.9108 - val_loss: 0.6137 - val_acc: 0.7402\n",
      "Epoch 5/15\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.1891 - acc: 0.9327\n",
      "Epoch 5: val_acc did not improve from 0.78346\n",
      "108/108 [==============================] - 6s 57ms/step - loss: 0.1891 - acc: 0.9327 - val_loss: 0.6844 - val_acc: 0.7585\n",
      "Epoch 5: early stopping\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(X_padded, y, epochs=15, callbacks=[es, mc], batch_size=64, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2e8e265b-4771-4d5a-8858-21db9c62a863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae2b4336-8b47-43ff-8991-24715e568cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238/238 [==============================] - 2s 7ms/step - loss: 0.1841 - acc: 0.9366\n",
      "train acc :  0.9365558624267578\n"
     ]
    }
   ],
   "source": [
    "print('train acc : ', model2.evaluate(X_padded, y)[1])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e06dcc12-e867-4df6-85d0-377d720f05d2",
   "metadata": {},
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "raw",
   "id": "375677af-b11b-42e6-97db-58a5eb50694b",
   "metadata": {},
   "source": [
    "conda install gensim"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9e54b442-0784-44d1-8d84-e4d220ca96af",
   "metadata": {},
   "source": [
    "pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "raw",
   "id": "38b805af-e2d7-42b1-a2b7-c0eb94f3b4b2",
   "metadata": {},
   "source": [
    "pip install --upgrade scipy"
   ]
  },
  {
   "cell_type": "raw",
   "id": "07a44335-5923-4ec1-9382-f3f96aee366b",
   "metadata": {},
   "source": [
    "conda update scipy"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b1b9ec88-45b6-4d40-8da1-1ce8c40c15aa",
   "metadata": {},
   "source": [
    "conda update gensim"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dac79c9b-42fb-4d33-91f1-afed332f9566",
   "metadata": {},
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "60a4ea5f-1f9c-429c-9743-af5c1f332aa2",
   "metadata": {},
   "source": [
    "conda update scipy numpy"
   ]
  },
  {
   "cell_type": "raw",
   "id": "976db8fb-5a2e-4ce6-9ae9-9445c198f632",
   "metadata": {},
   "source": [
    "pip install scipy==1.10.1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "50dd756c-09d5-4feb-8c71-e2ac2dde7f5e",
   "metadata": {},
   "source": [
    "conda install scipy==1.10.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "47642ebb-4fdc-4350-8867-0e5a1203db3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "w2v_model = Word2Vec(sentences=X_tokens, vector_size=60, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "19bbde63-3439-4383-8444-81c52eb62abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, 60))\n",
    "\n",
    "for word, i in word_to_index.items():\n",
    "    embedding_vector = w2v_model.wv[word]\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4157317c-9029-44f8-8edb-491a4b51b29e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 2)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_train['target']\n",
    "y = to_categorical(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "93484953-df74-4f7c-8d30-397dd15cb1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Embedding(vocab_size, embedding_dim))\n",
    "# model3.add(Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=60))\n",
    "model3.add(Bidirectional(LSTM(32, activation='relu')))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(32, activation='relu'))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(16, activation='relu'))\n",
    "model3.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "01604431-dcd3-4327-be10-b21c17416cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.6503 - acc: 0.6230\n",
      "Epoch 1: val_acc did not improve from 0.78346\n",
      "108/108 [==============================] - 4s 28ms/step - loss: 0.6503 - acc: 0.6230 - val_loss: 0.5132 - val_acc: 0.7388\n",
      "Epoch 2/15\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4085 - acc: 0.8270\n",
      "Epoch 2: val_acc did not improve from 0.78346\n",
      "108/108 [==============================] - 5s 43ms/step - loss: 0.4085 - acc: 0.8270 - val_loss: 0.5136 - val_acc: 0.7533\n",
      "Epoch 3/15\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.2796 - acc: 0.8896\n",
      "Epoch 3: val_acc did not improve from 0.78346\n",
      "108/108 [==============================] - 4s 40ms/step - loss: 0.2795 - acc: 0.8897 - val_loss: 0.7254 - val_acc: 0.7375\n",
      "Epoch 4/15\n",
      "107/108 [============================>.] - ETA: 0s - loss: 5.6066 - acc: 0.9134\n",
      "Epoch 4: val_acc did not improve from 0.78346\n",
      "108/108 [==============================] - 4s 41ms/step - loss: 5.6042 - acc: 0.9134 - val_loss: 39.8913 - val_acc: 0.7218\n",
      "Epoch 4: early stopping\n"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(X_padded, y, epochs=15, batch_size=64, validation_split=0.1, callbacks=[es,mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9a6ac9bb-be35-4219-b1fa-c84a29efc483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238/238 [==============================] - 1s 6ms/step - loss: 4.9595 - acc: 0.9274\n",
      "test acc :  0.9273610711097717\n"
     ]
    }
   ],
   "source": [
    "print('test acc : ', model3.evaluate(X_padded, y)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "211e9a3a-415b-487c-8faa-422806dc25d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(vocab_size, embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9c54505d-0da3-4604-9a1a-7f509f41d767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = model3.predict(X_test_padded)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "520738ed-289b-4e4a-9b12-92195ab1892c",
   "metadata": {},
   "source": [
    "print(y_pred, y_pred2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "642f3ad4-9c69-4645-9cd8-be1d6001b7d3",
   "metadata": {},
   "source": [
    "y_pred = (y_pred >= 0.5).astype(int)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca1f8a9-3224-4921-9f2c-52009cfa2adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = [np.argmax(p) for p in y_pred2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79b97b7-12f3-44e5-8e0c-c37ed03dfe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd5c9d3-5366-414c-bbec-ace4db580c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame({'id':df_test['id'], 'target':y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67267d4-bc6c-43a7-a4bb-008490f5f2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
