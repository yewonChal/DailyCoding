{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fa2c617-1b08-444b-9877-09ffd0629a40",
   "metadata": {},
   "source": [
    "## 인코더-디코더 방식은 입력과 출력의 길이가 다를 때 사용한다.(번역기, 텍스트 요약)\n",
    "\n",
    "# Seq2Seq\n",
    "### : 입력 시퀸스를 받아, 출력 시퀸스로 변환 모델(인코더와 디코더)\n",
    "- 인코더 : 이력 시퀸스를 받아 고정 길이의 벡터를 생성한다. 최종 상태를 디코더에 전달한다.\n",
    "- 디코더 : 인코더가 생성한 상태 벡터를 사용하여 출력 시퀸스를 생성한다. 상태벡터와 이전 시점의 출력 단어를 전달 받아 다음 단어를 예측한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "604eb304-8926-4c05-a9c1-084b09208d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de62e691-0a92-4e36-b2c8-640b8df4778f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232736"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = pd.read_csv('fra.txt', names=['src', 'tar', 'lic'], sep='\\t')\n",
    "\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52c818e6-2b0c-4160-84aa-049e8c9d9300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "      <th>lic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Va !</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Marche.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>En route !</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Bouge !</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut !</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   src         tar                                                lic\n",
       "0  Go.        Va !  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "1  Go.     Marche.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "2  Go.  En route !  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "3  Go.     Bouge !  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "4  Hi.     Salut !  CC-BY 2.0 (France) Attribution: tatoeba.org #5..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4e91764-e9c8-4dec-9ebe-42b2b365afa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17898</th>\n",
       "      <td>Tom is cautious.</td>\n",
       "      <td>Tom est prudent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7026</th>\n",
       "      <td>You're great.</td>\n",
       "      <td>T'assures.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5483</th>\n",
       "      <td>I went twice.</td>\n",
       "      <td>Je m'y suis rendue à deux reprises.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37283</th>\n",
       "      <td>Tom isn't reliable.</td>\n",
       "      <td>Tom n'est pas fiable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>I got an A.</td>\n",
       "      <td>J'ai eu un A.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       src                                  tar\n",
       "17898     Tom is cautious.                     Tom est prudent.\n",
       "7026         You're great.                           T'assures.\n",
       "5483         I went twice.  Je m'y suis rendue à deux reprises.\n",
       "37283  Tom isn't reliable.                Tom n'est pas fiable.\n",
       "2055           I got an A.                        J'ai eu un A."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del lines['lic']\n",
    "\n",
    "lines = lines[0:60000]\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a04c148-5420-43b4-9617-42781ac5d02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35926</th>\n",
       "      <td>She came to see me.</td>\n",
       "      <td>\\t Elle est venue me rendre visite. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29612</th>\n",
       "      <td>They kidnapped me.</td>\n",
       "      <td>\\t Ils m'ont enlevé. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41842</th>\n",
       "      <td>I wasn't busy today.</td>\n",
       "      <td>\\t Je n'étais pas occupé aujourd'hui. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38993</th>\n",
       "      <td>You're the teacher.</td>\n",
       "      <td>\\t Tu es l'enseignante. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15500</th>\n",
       "      <td>I have no proof.</td>\n",
       "      <td>\\t Je n'ai pas de preuve. \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        src                                       tar\n",
       "35926   She came to see me.    \\t Elle est venue me rendre visite. \\n\n",
       "29612    They kidnapped me.                   \\t Ils m'ont enlevé. \\n\n",
       "41842  I wasn't busy today.  \\t Je n'étais pas occupé aujourd'hui. \\n\n",
       "38993   You're the teacher.                \\t Tu es l'enseignante. \\n\n",
       "15500      I have no proof.              \\t Je n'ai pas de preuve. \\n"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.tar = lines.tar.apply(lambda x : '\\t ' + x + ' \\n')\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "60b3a1fa-bfb1-4607-91d6-bbaa802a6e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source 문장의 문자 집합 :  80\n",
      "target 문장의 문자 집합 :  102\n"
     ]
    }
   ],
   "source": [
    "src_vocab = set()\n",
    "for line in lines.src:\n",
    "    for char in line:\n",
    "        src_vocab.add(char)\n",
    "\n",
    "tar_vocab = set()\n",
    "for line in lines.tar:\n",
    "    for char in line:\n",
    "        tar_vocab.add(char)\n",
    "\n",
    "src_vocab_size = len(src_vocab) + 1\n",
    "tar_vocab_size = len(tar_vocab) + 1\n",
    "\n",
    "print('source 문장의 문자 집합 : ', src_vocab_size) # 80(<PAD> 토큰 포함)\n",
    "print('target 문장의 문자 집합 : ', tar_vocab_size) # 100(<PAD> 토큰 포함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61d2d920-027a-4dd9-9b69-d845a45f3426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source 문장의 문자 집합 :  80\n",
      "target 문장의 문자 집합 :  102\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(src_vocab) + 1\n",
    "tar_vocab_size = len(tar_vocab) + 1\n",
    "\n",
    "print('source 문장의 문자 집합 : ', src_vocab_size) # 80 (<PAD> 토큰 포함)\n",
    "print('target 문장의 문자 집합 : ', tar_vocab_size) # 100 (<PAD> 토큰 포함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca08a993-27f0-4ed8-866b-d4ae99a43804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t', '€', 'W', '-', 'f', '%', '9', 'ï', '.', '7']\n",
      "['t', 'W', '-', 'f', '%', '9', 'ï', '.', '7', 'û']\n"
     ]
    }
   ],
   "source": [
    "src_vocab = list(src_vocab)\n",
    "tar_vocab = list(tar_vocab)\n",
    "\n",
    "print(src_vocab[:10])\n",
    "print(tar_vocab[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "21172c4e-7bd1-4d28-8c1d-94698e4f5bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_to_index: {'t': 1, '€': 2, 'W': 3, '-': 4, 'f': 5, '%': 6, '9': 7, 'ï': 8, '.': 9, '7': 10, 'X': 11, 'w': 12, 'H': 13, ' ': 14, '8': 15, '2': 16, 'p': 17, 'Z': 18, ':': 19, 'Q': 20, 'U': 21, ',': 22, 'A': 23, 'r': 24, 'T': 25, 'z': 26, 'a': 27, 'V': 28, 'k': 29, 'N': 30, 'q': 31, '3': 32, 'J': 33, 'L': 34, 'c': 35, 's': 36, 'n': 37, 'G': 38, '5': 39, 'x': 40, 'y': 41, 'E': 42, '4': 43, 'm': 44, 'j': 45, 'F': 46, 'l': 47, '\"': 48, '/': 49, 'v': 50, 'e': 51, 'o': 52, '!': 53, 'Y': 54, 'B': 55, 'd': 56, 'P': 57, '0': 58, '?': 59, 'h': 60, '$': 61, 'R': 62, 'u': 63, 'g': 64, 'S': 65, 'O': 66, 'M': 67, 'K': 68, 'C': 69, \"'\": 70, 'D': 71, '’': 72, 'i': 73, 'I': 74, '&': 75, '1': 76, '6': 77, 'é': 78, 'b': 79}\n",
      "tar_to_index: {'t': 1, 'W': 2, '-': 3, 'f': 4, '%': 5, '9': 6, 'ï': 7, '.': 8, '7': 9, 'û': 10, 'X': 11, 'w': 12, 'H': 13, ' ': 14, '8': 15, '2': 16, 'p': 17, ':': 18, 'Q': 19, 'U': 20, ',': 21, 'A': 22, 'r': 23, '\\n': 24, '‽': 25, 'T': 26, 'Ê': 27, 'z': 28, 'a': 29, 'ù': 30, 'V': 31, 'k': 32, 'N': 33, 'œ': 34, 'q': 35, '3': 36, 'J': 37, 'L': 38, 'c': 39, 's': 40, 'À': 41, 'n': 42, 'G': 43, '5': 44, '\\xa0': 45, 'x': 46, '\\u2009': 47, '«': 48, 'y': 49, 'ê': 50, '»': 51, 'E': 52, '\\t': 53, 'ô': 54, '\\u202f': 55, 'ë': 56, '4': 57, 'â': 58, 'm': 59, 'j': 60, 'É': 61, 'F': 62, 'l': 63, '\"': 64, 'v': 65, 'o': 66, 'e': 67, '!': 68, 'Y': 69, 'B': 70, 'P': 71, 'd': 72, '0': 73, '?': 74, 'h': 75, 'Ô': 76, '$': 77, 'R': 78, 'Ç': 79, 'u': 80, '‘': 81, 'g': 82, 'S': 83, 'O': 84, 'M': 85, 'ç': 86, 'K': 87, 'C': 88, \"'\": 89, 'D': 90, '’': 91, 'i': 92, 'I': 93, 'è': 94, 'à': 95, '&': 96, '1': 97, '6': 98, 'î': 99, 'é': 100, 'b': 101}\n"
     ]
    }
   ],
   "source": [
    "src_to_index = {word: i+1 for i, word in enumerate(src_vocab)}\n",
    "tar_to_index = {word: i+1 for i, word in enumerate(tar_vocab)}\n",
    "\n",
    "print('src_to_index:', src_to_index)\n",
    "print('tar_to_index:', tar_to_index)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "caad26de-4677-43d7-8aaf-5f6e1ab3397b",
   "metadata": {},
   "source": [
    "lines.tar = lines.tar.apply(lambda x : '\\t ' + x + '\\n')\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa97500f-740c-4d24-a03e-71bcee416ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source encoding :  [[38, 52, 9], [38, 52, 9], [38, 52, 9], [38, 52, 9], [13, 73, 9]]\n"
     ]
    }
   ],
   "source": [
    "encoder_input = []\n",
    "\n",
    "for line in lines.src:\n",
    "    encoded_line = []\n",
    "    for char in line:\n",
    "        encoded_line.append(src_to_index[char])\n",
    "    encoder_input.append(encoded_line)\n",
    "\n",
    "print('source encoding : ', encoder_input[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f82b883-d64e-4d30-bf88-78a9d21e4a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target encoding :  [[14, 31, 29, 14, 68, 14, 24], [14, 85, 29, 23, 39, 75, 67, 8, 14, 24], [14, 52, 42, 14, 23, 66, 80, 1, 67, 14, 68, 14, 24], [14, 70, 66, 80, 82, 67, 14, 68, 14, 24], [14, 83, 29, 63, 80, 1, 14, 68, 14, 24]]\n"
     ]
    }
   ],
   "source": [
    "decoder_target = []\n",
    "\n",
    "for line in lines.tar:\n",
    "    time=0\n",
    "    encoded_line = []\n",
    "    for char in line:\n",
    "        if time > 0:\n",
    "            encoded_line.append(tar_to_index[char])\n",
    "        time += 1\n",
    "    decoder_target.append(encoded_line)\n",
    "\n",
    "print('target encoding : ', decoder_target[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "67cae63d-54a0-4227-b5cc-77e78e2baf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source 문장 최대 길이 :  22\n",
      "target 문장 최대 길이 :  76\n"
     ]
    }
   ],
   "source": [
    "max_src_len = max([len(line) for line in lines.src])\n",
    "max_tar_len = max([len(line) for line in lines.tar])\n",
    "\n",
    "print('source 문장 최대 길이 : ', max_src_len)\n",
    "print('target 문장 최대 길이 : ', max_tar_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2b58053-1f9f-4f14-a0c0-18c29aa8a12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩처리\n",
    "encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5fb2a9fd-0f47-4687-aac0-04ba283b3847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38 52  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] [14 31 29 14 68 14 24  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input[0], decoder_target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e54738dc-7042-46c6-8720-2cf39bffae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = to_categorical(encoder_input)\n",
    "decoder_target = to_categorical(decoder_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1451258a-ef7b-418f-9d6f-56063fbeecf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target encoding :  [[53, 14, 31, 29, 14, 68, 14, 24], [53, 14, 85, 29, 23, 39, 75, 67, 8, 14, 24], [53, 14, 52, 42, 14, 23, 66, 80, 1, 67, 14, 68, 14, 24], [53, 14, 70, 66, 80, 82, 67, 14, 68, 14, 24], [53, 14, 83, 29, 63, 80, 1, 14, 68, 14, 24]]\n"
     ]
    }
   ],
   "source": [
    "decoder_input = []\n",
    "for line in lines.tar:\n",
    "    encoded_line = []\n",
    "    for char in line:\n",
    "        encoded_line.append(tar_to_index[char])\n",
    "\n",
    "    decoder_input.append(encoded_line)\n",
    "\n",
    "print('target encoding : ', decoder_input[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8922b8be-2465-4d2a-8d3e-95c2adb720fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력(영어) -> 출력(프랑스어) 이전 인코더의 출력 뿐만 아니라 정답을 같이 디코더의 입력으로 전달받아 모델의 성능을 향상시키겠다.\n",
    "decoder_input = pad_sequences(decoder_input, maxlen = max_tar_len, padding = 'post')\n",
    "decoder_input = to_categorical(decoder_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "020f1967-8aa7-44e8-8f6f-3980b014e63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "00e07aab-b774-4d66-bd48-00f1472a506c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 10:10:05.083724: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-15 10:10:05.085795: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-15 10:10:05.086783: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "# 인코더 : enoder LSTM에서 히든 상태와 셀 상태를 반환\n",
    "encoder_inputs = Input(shape=(None, src_vocab_size))\n",
    "encoder_lstm = LSTM(units=256, return_state=True) # 인코더 상태 return_state\n",
    "\n",
    "_, state_h, state_c = encoder_lstm(encoder_inputs) # 히든 상태, 셀 상태\n",
    "\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "92153c3c-cb53-49b5-86cc-c1e696c58103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 10:10:05.565667: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-15 10:10:05.567595: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-15 10:10:05.568730: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "# 디코더 : 인코더 상태를 전달받아 최종 출력 반환\n",
    "decoder_inputs = Input(shape=(None, tar_vocab_size))\n",
    "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "\n",
    "decoder_dense = Dense(tar_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a450bb95-584f-4dae-be16-9a9342990fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcc002d-b07a-4b65-802a-b072b6b7e588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 10:10:05.838368: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-15 10:10:05.839754: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-15 10:10:05.840608: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-07-15 10:10:05.951263: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-15 10:10:05.952202: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-15 10:10:05.953080: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-07-15 10:10:06.434819: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-15 10:10:06.435941: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-15 10:10:06.436841: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-07-15 10:10:06.545900: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-15 10:10:06.546880: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-15 10:10:06.547764: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 [==============================] - ETA: 0s - loss: 0.8675 - acc: 0.7733"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 10:15:07.059827: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-15 10:15:07.060712: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-15 10:15:07.061669: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-07-15 10:15:07.170507: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-15 10:15:07.171299: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-15 10:15:07.171978: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 [==============================] - 314s 739ms/step - loss: 0.8675 - acc: 0.7733 - val_loss: 0.7282 - val_acc: 0.7857\n",
      "Epoch 2/40\n",
      "422/422 [==============================] - 335s 795ms/step - loss: 0.5228 - acc: 0.8457 - val_loss: 0.5896 - val_acc: 0.8250\n",
      "Epoch 3/40\n",
      "422/422 [==============================] - 347s 822ms/step - loss: 0.4327 - acc: 0.8703 - val_loss: 0.5108 - val_acc: 0.8460\n",
      "Epoch 4/40\n",
      "422/422 [==============================] - 313s 742ms/step - loss: 0.3812 - acc: 0.8853 - val_loss: 0.4640 - val_acc: 0.8611\n",
      "Epoch 5/40\n",
      "422/422 [==============================] - 326s 772ms/step - loss: 0.3471 - acc: 0.8951 - val_loss: 0.4333 - val_acc: 0.8695\n",
      "Epoch 6/40\n",
      "422/422 [==============================] - 329s 781ms/step - loss: 0.3226 - acc: 0.9023 - val_loss: 0.4106 - val_acc: 0.8762\n",
      "Epoch 7/40\n",
      "422/422 [==============================] - 343s 813ms/step - loss: 0.3034 - acc: 0.9079 - val_loss: 0.3931 - val_acc: 0.8818\n",
      "Epoch 8/40\n",
      "422/422 [==============================] - 260s 614ms/step - loss: 0.2878 - acc: 0.9124 - val_loss: 0.3799 - val_acc: 0.8856\n",
      "Epoch 9/40\n",
      "422/422 [==============================] - 174s 413ms/step - loss: 0.2752 - acc: 0.9161 - val_loss: 0.3711 - val_acc: 0.8881\n",
      "Epoch 10/40\n",
      "422/422 [==============================] - 177s 419ms/step - loss: 0.2642 - acc: 0.9195 - val_loss: 0.3622 - val_acc: 0.8907\n",
      "Epoch 11/40\n",
      "422/422 [==============================] - 184s 436ms/step - loss: 0.2547 - acc: 0.9222 - val_loss: 0.3557 - val_acc: 0.8934\n",
      "Epoch 12/40\n",
      "422/422 [==============================] - 311s 739ms/step - loss: 0.2462 - acc: 0.9246 - val_loss: 0.3490 - val_acc: 0.8956\n",
      "Epoch 13/40\n",
      "422/422 [==============================] - 323s 766ms/step - loss: 0.2387 - acc: 0.9268 - val_loss: 0.3435 - val_acc: 0.8971\n",
      "Epoch 14/40\n",
      "422/422 [==============================] - 324s 768ms/step - loss: 0.2320 - acc: 0.9288 - val_loss: 0.3404 - val_acc: 0.8979\n",
      "Epoch 15/40\n",
      "422/422 [==============================] - 324s 768ms/step - loss: 0.2258 - acc: 0.9306 - val_loss: 0.3394 - val_acc: 0.8983\n",
      "Epoch 16/40\n",
      "422/422 [==============================] - 308s 730ms/step - loss: 0.2200 - acc: 0.9324 - val_loss: 0.3347 - val_acc: 0.9006\n",
      "Epoch 17/40\n",
      "422/422 [==============================] - 311s 737ms/step - loss: 0.2149 - acc: 0.9338 - val_loss: 0.3338 - val_acc: 0.9003\n",
      "Epoch 18/40\n",
      "422/422 [==============================] - 313s 743ms/step - loss: 0.2101 - acc: 0.9352 - val_loss: 0.3337 - val_acc: 0.9010\n",
      "Epoch 19/40\n",
      "422/422 [==============================] - 355s 843ms/step - loss: 0.2055 - acc: 0.9367 - val_loss: 0.3307 - val_acc: 0.9022\n",
      "Epoch 20/40\n",
      "422/422 [==============================] - 327s 774ms/step - loss: 0.2013 - acc: 0.9378 - val_loss: 0.3321 - val_acc: 0.9019\n",
      "Epoch 21/40\n",
      "422/422 [==============================] - 354s 840ms/step - loss: 0.1973 - acc: 0.9390 - val_loss: 0.3308 - val_acc: 0.9024\n",
      "Epoch 22/40\n",
      "422/422 [==============================] - 337s 799ms/step - loss: 0.1935 - acc: 0.9402 - val_loss: 0.3304 - val_acc: 0.9030\n",
      "Epoch 23/40\n",
      "422/422 [==============================] - 350s 829ms/step - loss: 0.1899 - acc: 0.9413 - val_loss: 0.3325 - val_acc: 0.9026\n",
      "Epoch 24/40\n",
      "422/422 [==============================] - 348s 824ms/step - loss: 0.1864 - acc: 0.9422 - val_loss: 0.3306 - val_acc: 0.9034\n",
      "Epoch 25/40\n",
      "422/422 [==============================] - 351s 833ms/step - loss: 0.1832 - acc: 0.9432 - val_loss: 0.3317 - val_acc: 0.9034\n",
      "Epoch 26/40\n",
      "422/422 [==============================] - 351s 831ms/step - loss: 0.1802 - acc: 0.9441 - val_loss: 0.3317 - val_acc: 0.9041\n",
      "Epoch 27/40\n",
      "422/422 [==============================] - 351s 832ms/step - loss: 0.1771 - acc: 0.9449 - val_loss: 0.3344 - val_acc: 0.9034\n",
      "Epoch 28/40\n",
      "422/422 [==============================] - 339s 804ms/step - loss: 0.1743 - acc: 0.9458 - val_loss: 0.3348 - val_acc: 0.9035\n",
      "Epoch 29/40\n",
      "422/422 [==============================] - 345s 818ms/step - loss: 0.1717 - acc: 0.9465 - val_loss: 0.3378 - val_acc: 0.9033\n",
      "Epoch 30/40\n",
      "422/422 [==============================] - 372s 882ms/step - loss: 0.1691 - acc: 0.9475 - val_loss: 0.3373 - val_acc: 0.9038\n",
      "Epoch 31/40\n",
      "422/422 [==============================] - 389s 922ms/step - loss: 0.1666 - acc: 0.9480 - val_loss: 0.3375 - val_acc: 0.9040\n",
      "Epoch 32/40\n",
      "422/422 [==============================] - 463s 1s/step - loss: 0.1641 - acc: 0.9487 - val_loss: 0.3399 - val_acc: 0.9038\n",
      "Epoch 33/40\n",
      "422/422 [==============================] - 670s 2s/step - loss: 0.1618 - acc: 0.9494 - val_loss: 0.3408 - val_acc: 0.9039\n",
      "Epoch 34/40\n",
      "422/422 [==============================] - 697s 2s/step - loss: 0.1597 - acc: 0.9502 - val_loss: 0.3437 - val_acc: 0.9035\n",
      "Epoch 35/40\n",
      "422/422 [==============================] - ETA: 0s - loss: 0.1575 - acc: 0.9508"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "history = model.fit(\n",
    "    x=[encoder_input, decoder_input],\n",
    "    y=decoder_target,\n",
    "    batch_size=128,\n",
    "    epochs=40,\n",
    "    validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32560304-bd99-4247-874a-965489c0b104",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9044c21d-340d-4814-b37d-1f6373768cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전 상태\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# 초기상태를 이전 시점의 상태로 초기화\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state = decoder_states_inputs)\n",
    "\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "\n",
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs = [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439e1f1a-7b2c-4166-92ef-68cd1f057467",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_src = dict(i, char) for char, i in src_to_index.items())\n",
    "index_to_tar = dict(i, char) for char, i in tar_to_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ee5fb1-8aca-4af8-bbe9-14affa7f34b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predicct(input_seq) # 입력을 기준으로 상태 반환\n",
    "\n",
    "    target_seq = np.zeros((1, 1, tar_vocab_size)) # 원-핫 벡터 생성\n",
    "    target_seq[0, 0, tar_to_index['\\t']] = 1. # <SOS> 문장이 시작되는 \n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    while not stop_condition:\n",
    "        # 이전 시점의 상태를 현 시점의 초기 상태로 설정\n",
    "        output_tokens, h, x = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :]) # 가장 높은 결과로 예측\n",
    "        sampled_char = index_to_tar[sampled_token_index] # 예측 결과를 문자로 변환\n",
    "        decoded_sentence += sampled_char # 문자를 추가\n",
    "\n",
    "        # <EOS> 문장의 끝에 도달하거나 최대 길이를 넘어가면 종료\n",
    "        if (sampled_char == '\\n' or len(decoded_sentence) > max_tar_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "        target_seq[0, 0, sampled_token_index] = 1. # 현재 시점의 결과를 다음 시점의 입력으로 사용(tar_to_index[sampled_char])\n",
    "\n",
    "        states_value = [h, c] # 현재 시점의 상태를 다음 시점의 입력할 상태로 사용\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca83a05f-a7b4-40ef-8e94-cc986f537ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq_index in [2, 55, 123, 506, 1001]:\n",
    "    input_seq = encoder_input[seq_index:seq_index+1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print('입력 문장 : ', lines.src[seq_index])\n",
    "    print('정답 문장 : ', lines.tar[seq_index][2:len(lines.tar[seq_index])-1])\n",
    "    print('번역 문장 : ', decoded_sentence[1:len(decoded_sentence)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a5916f-3629-49c3-9741-26a056665abf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
