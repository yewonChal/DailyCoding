{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80787969-82dd-43ff-a937-446bb44b6b4a",
   "metadata": {},
   "source": [
    "# 태깅(Tagging) \n",
    "### : NLP에서 각 단어나 토큰에 대해 관련된 정보를 할당하는 작업\n",
    "\n",
    "1. 품사 태깅(Part-of-Speach Tagging) : 각 단어나 토큰에 대해 단어의 품사(명사, 형용사, 동사 등)을 할당한다.\n",
    "\n",
    "ex) The cat sat on the mat -> ['the', 'cat', 'sat', 'on', 'the', 'mat'] -> the:DT, cat:NN, sat:VBD, on:IN, the:DT, mat:NN\n",
    "- DT : 한정사(determiner)\n",
    "- NN : 명사(Noun)\n",
    "- VBD : 과거형 동사(past tense verb)\n",
    "- IN : 전치사(preposition)\n",
    "\n",
    "2. 명명된 개체 인식(Named Entity Recognition, NER) : NLP에서 사람, 조직, 장소, 날짜 등 명명된 개체를 인식하고 태깅한다.\n",
    "\n",
    "ex) Barack Obama was born in Hawaii. -> Barack:PERSON, Obama:PERSON, Hawaii:LOCATION\n",
    "\n",
    "3. 의존 구문 분석(Dependency Parsing) : NLP에서 각 단어의 종속 관계를 식별하고 태깅한다.\n",
    "\n",
    "ex) She enjoys playing piano. -> 중심(enjoys 동사), she 주어, playing 목적어\n",
    "\n",
    "4. 문법적 관계 태깅(Constituency Parsing) : 문장의 구성 요소를 분석해서 계층 트리 구조로 표현 및 태깅한다.\n",
    "\n",
    "5. 감정 분석(Sentiment Analysis) : 각 문장이나 토큰에 대해 감정을 태깅할 수 있다.\n",
    "\n",
    "ex) I love NLP. (positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1361c352-91b0-4e56-b65d-0f6ec0e0292c",
   "metadata": {},
   "source": [
    "![image.png](attachment:69f2e327-548f-46b0-abdc-94eb300a7f32.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4315431-fcfe-468d-9817-6a451f7c8c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/jeon-yewon/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2e6f19b-15d9-4faa-b391-b4a94cbba8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to /Users/jeon-\n",
      "[nltk_data]     yewon/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "daced92f-5e3a-4700-af09-e9dd2ee2664b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /Users/jeon-\n",
      "[nltk_data]     yewon/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9993d18a-733b-4269-a84e-0d4b7f3b3ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('cat', 'NN'), ('sat', 'VBD'), ('on', 'IN'), ('the', 'DT'), ('mat', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "text = 'The cat sat on the mat'\n",
    "\n",
    "tokens = word_tokenize(text) # 토큰화\n",
    "\n",
    "tagged = pos_tag(tokens) # 품사 태깅\n",
    "\n",
    "print(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58be3b2e-a392-4103-a020-b103175907f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Barack', 'NNP'), ('Obama', 'NNP'), ('was', 'VBD'), ('born', 'VBN'), ('in', 'IN'), ('Hawaii', 'NNP'), ('.', '.')]\n",
      "(S\n",
      "  (PERSON Barack/NNP)\n",
      "  (PERSON Obama/NNP)\n",
      "  was/VBD\n",
      "  born/VBN\n",
      "  in/IN\n",
      "  (GPE Hawaii/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "from nltk import ne_chunk\n",
    "\n",
    "text = 'Barack Obama was born in Hawaii.'\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "tags = pos_tag(tokens)\n",
    "entities = ne_chunk(tags)\n",
    "\n",
    "print(tags)\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdebbd13-35ec-4bf8-9018-c87e4aad4d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Barack Obama', 'PERSON'), ('Hawaii', 'GPE')]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm') # spacya의 사전 학습 모델(토큰화, POS 태깅, NER 등이 포함)\n",
    "\n",
    "text = 'Barack Obama was born in Hawaii.'\n",
    "doc = nlp(text)\n",
    "\n",
    "entities = [(entity.text, entity.label_) for entity in doc.ents]\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed2049b0-2ef9-4271-9541-0f3da14547b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP The/DT quick/JJ brown/NN)\n",
      "  (NP fox/NN)\n",
      "  jumps/VBZ\n",
      "  over/IN\n",
      "  (NP the/DT lazy/JJ dog/NN))\n"
     ]
    }
   ],
   "source": [
    "from nltk import RegexpParser\n",
    "\n",
    "text = 'The quick brown fox jumps over the lazy dog'\n",
    "tokens = word_tokenize(text)\n",
    "tags = pos_tag(tokens)\n",
    "\n",
    "# 청킹 규칙 정의 : 품사 태그의 패턴을 정의하여 특정 부분을 추출한다.\n",
    "grammer = 'NP: {<DT>?<JJ>*<NN>}'\n",
    "\n",
    "cp = RegexpParser(grammer) # 청킹 파서 생성\n",
    "tree = cp.parse(tags) # 품사 태깅된 토큰 리스트을 통해 청킹 트리를 생성한다.\n",
    "\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636febb2-5c9c-40c1-9146-7e6b072376b4",
   "metadata": {},
   "source": [
    "# 청킹 규칙 정의 \n",
    "### : 품사 태그의 패턴을 정의하여 특정 부분을 추출한다.\n",
    "\n",
    "1. 기본\n",
    "- {} : 패턴을 정의하는 부분\n",
    "\n",
    "2. 반복 및 선택\n",
    "- ? : 0개 또는 1개의 품사 태그\n",
    "- * : 0개 이상 품사 태그\n",
    "- + : 1개 이상 품사 태그\n",
    "\n",
    "(S\n",
    "  (NP The/DT quick/JJ brown/NN)\n",
    "  (NP fox/NN)\n",
    "  jumps/VBZ\n",
    "  over/IN\n",
    "  (NP the/DT lazy/JJ dog/NN))\n",
    "\n",
    "S ... : 문장(Sentence)을 의미하는 최상위 노드\n",
    "(NP The/DT quick/JJ brown/NN) (NP fox/NN) : 명사구 (The quick brown fox)\n",
    "(NP the/DT lazy/JJ dog/NN) : 명사구 (The lazy dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dfab89b-a70c-4af4-b77a-9bf61a658a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa16386e-c42e-4624-8409-1fc7851acf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to /Users/jeon-\n",
      "[nltk_data]     yewon/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/treebank.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('treebank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30c43e18-1c77-4077-855b-c8423797eb22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3914"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sentences = nltk.corpus.treebank.tagged_sents()\n",
    "len(tagged_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "799ea84a-2d46-4a58-9401-04ab566e75af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(tagged_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25fc6372-acc5-467f-a48a-0e0a363b4045",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, pos_tags = [], [] # 단어와 태그 부분을 나누어 작업 진행\n",
    "\n",
    "for tagged_sentence in tagged_sentences:\n",
    "    sentence, tag_info = zip(*tagged_sentence)\n",
    "    sentences.append(list(sentence))\n",
    "    pos_tags.append(list(tag_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e899368f-da00-49bd-8850-b7f6cc78686f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1607d4f-3fc6-4e93-92bd-8f113320a89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', ',', 'MD', 'VB', 'DT', 'NN', 'IN', 'DT', 'JJ', 'NN', 'NNP', 'CD', '.']\n"
     ]
    }
   ],
   "source": [
    "print(pos_tags[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91e49a8-672f-4341-a1d4-5d26bac3e191",
   "metadata": {},
   "source": [
    "### 모델로 태깅처리(x(sentences) 데이터로 y(pos_tags) 데이터 예측하기))\n",
    "1. 데이터 분리(sentences, pos_tags)\n",
    "2. 토큰화(두 가지 모두 단어 형식)\n",
    "* 그동안은 숫자/숫자 또는 숫자/문자를 기준으로 토큰화 처리 했다면, 이번 코드에선 문자/문자를 기준으로 토큰화 처리하는 것에 집중하여 살펴본다.\n",
    "\n",
    "3. 패딩(Padding) 작업\n",
    "4. 분류\n",
    "5. 모델학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fcb3c58-6ed6-4d29-ad6f-86cdca9ad925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(samples):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(samples)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31e99ba3-4514-42e4-a192-eca92eede3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = tokenize(sentences)\n",
    "tag_tokenizer = tokenize(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4679dabe-edec-419b-8a93-0a2c225750dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 :  11388\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(src_tokenizer.word_index) + 1\n",
    "print('단어 집합의 크기 : ', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c23c69e4-0c8a-4f52-974c-c5025d997972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "태깅 집합의 크기 :  47\n"
     ]
    }
   ],
   "source": [
    "tag_size = len(tar_tokenizer.word_index) + 1\n",
    "print('태깅 집합의 크기 : ', tag_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3bcfb8fa-a5bc-4ca8-af52-4b7e3a1b4222",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = src_tokenizer.texts_to_sequences(sentences)\n",
    "y_train = tag_tokenizer.texts_to_sequences(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea588c53-cf80-4f09-9197-e34434744376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5601, 3746, 1, 2024, 86, 331, 1, 46, 2405, 2, 131, 27, 6, 2025, 332, 459, 2026, 3] [3, 3, 8, 10, 6, 7, 8, 21, 13, 4, 1, 2, 4, 7, 1, 3, 10, 9]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0], y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83aa50da-11ae-47cd-a9ea-ecd75be04782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대 길이 :  271\n",
      "평균 길이 :  25.722023505365357\n"
     ]
    }
   ],
   "source": [
    "print('최대 길이 : ', max(len(l) for l in X_train))\n",
    "print('평균 길이 : ', (sum(map(len, X_train))/len(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72909bb5-48c6-4324-bbb2-a09321f5d22b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(s) for s in X_train], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e81bb82c-110f-4d69-917f-0722ec374184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대 길이 :  271\n",
      "평균 길이 :  25.722023505365357\n"
     ]
    }
   ],
   "source": [
    "print('최대 길이 : ', max(len(l) for l in y_train))\n",
    "print('평균 길이 : ', (sum(map(len, y_train))/len(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8033d3f5-c35b-4644-ac07-ed7c8de87fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 단어별 태그임으로 최대 길이와 평균 길이가 동일한 모습을 살펴볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20ba4815-20ef-40b2-9925-0dfef38c86b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 150\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=max_len)\n",
    "y_train = pad_sequences(y_train, padding='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c10da6e4-af75-4e9c-b6c6-eeddcacdc698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5601 3746    1 2024   86  331    1   46 2405    2  131   27    6 2025\n",
      "   332  459 2026    3    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0]\n",
      " [  31 3746   20  177    4 5602 2915    1    2 2916  637  147    3    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "803a676f-6b09-4825-af09-7a84f270ae46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  3  8 ...  0  0  0]\n",
      " [ 3  3 17 ...  0  0  0]\n",
      " [ 3  3  8 ...  0  0  0]\n",
      " ...\n",
      " [ 3 30  3 ...  0  0  0]\n",
      " [ 6 11 12 ...  0  0  0]\n",
      " [ 3 11  5 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae8c88fc-c61d-4e1f-ab29-dd9784b45137",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "55f8f391-0ff0-4001-a1c9-ec85ad63a33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3131, 150) (783, 150)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bf048f8f-1a7b-4d1f-819f-5a053b95c670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3131, 150) (783, 150)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0ee20a7e-b5e8-4438-8fe1-f6c15d24ff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, InputLayer, Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "790fce75-1550-4898-9eba-bc188d80e290",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, None, 128)         1457664   \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, None, 128)         131584    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, None, 47)          6063      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1595311 (6.09 MB)\n",
      "Trainable params: 1595311 (6.09 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "embedding_dim = 128\n",
    "hidden_units = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(LSTM(hidden_units, return_sequences=True)) # 각 타임스탭마다 출력\n",
    "model.add(Dense(tag_size, activation='softmax')) # + TimeDistributed Dense : 각 타임스탭에 지정된 레이어를 개별적으로 적용\n",
    "# binary_crossentropy : 원-핫 인코딩\n",
    "# sparse_categorical_crossentropy\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d866e7c7-5c21-41de-9ecd-2b549a6a70de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - ETA: 0s - loss: 1.8499 - accuracy: 0.7932WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 12s 477ms/step - loss: 1.8499 - accuracy: 0.7932 - val_loss: 0.9077 - val_accuracy: 0.8251\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.7638 - accuracy: 0.8319WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 14s 576ms/step - loss: 0.7638 - accuracy: 0.8319 - val_loss: 0.7203 - val_accuracy: 0.8313\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.6747 - accuracy: 0.8348WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 14s 546ms/step - loss: 0.6747 - accuracy: 0.8348 - val_loss: 0.6643 - val_accuracy: 0.8274\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.6287 - accuracy: 0.8321WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 18s 747ms/step - loss: 0.6287 - accuracy: 0.8321 - val_loss: 0.6252 - val_accuracy: 0.8288\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.5941 - accuracy: 0.8373WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 19s 763ms/step - loss: 0.5941 - accuracy: 0.8373 - val_loss: 0.5922 - val_accuracy: 0.8391\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.5641 - accuracy: 0.8473WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 13s 501ms/step - loss: 0.5641 - accuracy: 0.8473 - val_loss: 0.5707 - val_accuracy: 0.8462\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.5418 - accuracy: 0.8520WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 12s 486ms/step - loss: 0.5418 - accuracy: 0.8520 - val_loss: 0.5495 - val_accuracy: 0.8515\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.5244 - accuracy: 0.8562WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 13s 505ms/step - loss: 0.5244 - accuracy: 0.8562 - val_loss: 0.5354 - val_accuracy: 0.8546\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.5103 - accuracy: 0.8593WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 13s 505ms/step - loss: 0.5103 - accuracy: 0.8593 - val_loss: 0.5220 - val_accuracy: 0.8564\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.4980 - accuracy: 0.8621WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 13s 519ms/step - loss: 0.4980 - accuracy: 0.8621 - val_loss: 0.5078 - val_accuracy: 0.8611\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.4844 - accuracy: 0.8690WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 13s 509ms/step - loss: 0.4844 - accuracy: 0.8690 - val_loss: 0.4945 - val_accuracy: 0.8685\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.4656 - accuracy: 0.8760WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 12s 493ms/step - loss: 0.4656 - accuracy: 0.8760 - val_loss: 0.4718 - val_accuracy: 0.8737\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.4390 - accuracy: 0.8852WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 13s 505ms/step - loss: 0.4390 - accuracy: 0.8852 - val_loss: 0.4402 - val_accuracy: 0.8867\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.4045 - accuracy: 0.9021WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 12s 471ms/step - loss: 0.4045 - accuracy: 0.9021 - val_loss: 0.3973 - val_accuracy: 0.9059\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.3642 - accuracy: 0.9133WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 12s 482ms/step - loss: 0.3642 - accuracy: 0.9133 - val_loss: 0.3593 - val_accuracy: 0.9146\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.3263 - accuracy: 0.9219WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 12s 495ms/step - loss: 0.3263 - accuracy: 0.9219 - val_loss: 0.3233 - val_accuracy: 0.9215\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.2903 - accuracy: 0.9299WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 12s 490ms/step - loss: 0.2903 - accuracy: 0.9299 - val_loss: 0.2892 - val_accuracy: 0.9295\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.2563 - accuracy: 0.9374WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 12s 491ms/step - loss: 0.2563 - accuracy: 0.9374 - val_loss: 0.2574 - val_accuracy: 0.9367\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.2240 - accuracy: 0.9450WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 13s 505ms/step - loss: 0.2240 - accuracy: 0.9450 - val_loss: 0.2274 - val_accuracy: 0.9444\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.1932 - accuracy: 0.9550WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 13s 508ms/step - loss: 0.1932 - accuracy: 0.9550 - val_loss: 0.1993 - val_accuracy: 0.9534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a36a7a30>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# callback 지정\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "mc = ModelCheckpoint('best_model.keras', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=20, validation_data=(X_test, y_test), callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0479bf5d-4d92-4bfa-82e1-b308e4ac5226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 2s 82ms/step - loss: 0.1993 - accuracy: 0.9534\n",
      "test acc :  [0.19933128356933594, 0.9533674120903015]\n"
     ]
    }
   ],
   "source": [
    "print('test acc : ', model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "28b41859-7245-4cd5-8dff-f17783a4c36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "단어             |실제값  |예측값\n",
      "-----------------------------------\n",
      "sharedata        : NNP     VBP\n",
      "develops         : VBZ     VB\n",
      "and              : CC      WRB\n",
      "markets          : VBZ     WP$\n",
      "low-cost         : JJ      WP$\n",
      "software         : NN      WP$\n",
      ",                : ,       WP$\n",
      "peripheral       : JJ      WP$\n",
      "equipment        : NN      VBP\n",
      "and              : CC      VBP\n",
      "accessories      : NNS     SYM\n",
      "for              : IN      SYM\n",
      "computers        : NNS     PDT\n",
      ".                : .       PDT\n"
     ]
    }
   ],
   "source": [
    "# 결과확인\n",
    "index_to_word = src_tokenizer.index_word\n",
    "index_to_tag = tar_tokenizer.index_word\n",
    "\n",
    "i = 30\n",
    "y_predicted = model.predict(np.array([X_test[i]]))\n",
    "y_predicted = np.argmax(y_predicted, axis=-1)\n",
    "\n",
    "print('{:15}|{:5}|{}'.format('단어', '실제값', '예측값'))\n",
    "print('-'*35)\n",
    "\n",
    "for word, tag, pred in zip(X_test[i], y_test[i], y_predicted[0]):\n",
    "    if word!=0:\n",
    "        print('{:17}: {:7} {}'.format(index_to_word[word], index_to_tag[tag].upper(), index_to_tag[pred].upper()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2595f367-7155-4dc1-bc48-807662dcd423",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
