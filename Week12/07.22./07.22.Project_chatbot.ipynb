{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c791e89-de5f-4a03-a6d9-d63a0ceadee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bab7f15-27d1-4c2e-a26c-b2ef707c45ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ChatBotData.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e0cd5299-c09c-4318-a166-c55492b27800",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = df['Q'].tolist()\n",
    "answers = df['A'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bbd6c78a-9810-4a8a-b737-a24e59713667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 전처리\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9가-힣\\s]\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a9115fb2-923c-4a73-8619-c51ff7e7949b",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [preprocess_text(q) for q in questions]\n",
    "answers = [\"<start> \" + preprocess_text(a) + \" <end>\" for a in answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ad810b83-72d8-46dd-880b-ce0f2a55a3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Q, test_Q, train_A, test_A = train_test_split(questions, answers, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "87ec0230-b579-4ada-b4e4-b90b4b621d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters='')\n",
    "tokenizer.fit_on_texts(train_Q + train_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8f630ac8-43c5-4abf-9090-761bc568411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if '<start>' not in tokenizer.word_index:\n",
    "    tokenizer.word_index['<start>'] = len(tokenizer.word_index) + 1\n",
    "if '<end>' not in tokenizer.word_index:\n",
    "    tokenizer.word_index['<end>'] = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f0f4752f-e674-4ce8-88c0-3d2d227c2652",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Q_sequences = tokenizer.texts_to_sequences(train_Q)\n",
    "train_A_sequences = tokenizer.texts_to_sequences(train_A)\n",
    "test_Q_sequences = tokenizer.texts_to_sequences(test_Q)\n",
    "test_A_sequences = tokenizer.texts_to_sequences(test_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ffe3e664-7b8b-4c9f-b894-f14c8b9e9a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩\n",
    "max_seq_length = max(max(len(seq) for seq in train_Q_sequences), max(len(seq) for seq in train_A_sequences))\n",
    "train_Q_padded = pad_sequences(train_Q_sequences, maxlen=max_seq_length, padding='post')\n",
    "train_A_padded = pad_sequences(train_A_sequences, maxlen=max_seq_length, padding='post')\n",
    "test_Q_padded = pad_sequences(test_Q_sequences, maxlen=max_seq_length, padding='post')\n",
    "test_A_padded = pad_sequences(test_A_sequences, maxlen=max_seq_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "29d29340-f759-46b7-97b1-6cc40a80be8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b751b4c5-4903-4929-b66c-8eea57214ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = 256\n",
    "units = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c69a1d59-39dd-4174-9d7c-7fa270429256",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb = Embedding(vocab_size, embedding_dim)(encoder_inputs)\n",
    "encoder_lstm = LSTM(units, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c6a50eca-db8c-4bca-8492-30d67810c197",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb = Embedding(vocab_size, embedding_dim)(decoder_inputs)\n",
    "decoder_lstm = LSTM(units, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
    "decoder_dense = Dense(vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "28723028-4bbc-4415-9908-128008f0405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1d953718-0cf3-4b79-b805-61cbe6692281",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "61460aab-8f25-4627-860a-d4fb82c126e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_11 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, None, 256)    4660480     ['input_10[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)        (None, None, 256)    4660480     ['input_11[0][0]']               \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, 512),        1574912     ['embedding_3[0][0]']            \n",
      "                                 (None, 512),                                                     \n",
      "                                 (None, 512)]                                                     \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)                  [(None, None, 512),  1574912     ['embedding_4[0][0]',            \n",
      "                                 (None, 512),                     'lstm_3[0][1]',                 \n",
      "                                 (None, 512)]                     'lstm_3[0][2]']                 \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, None, 18205)  9339165     ['lstm_4[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,809,949\n",
      "Trainable params: 21,809,949\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fa63f0ef-a344-460a-a68d-6075f4791dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_decoder_input_sequences = np.array([seq[:-1] for seq in train_A_padded])\n",
    "train_decoder_target_sequences = np.expand_dims(np.array([seq[1:] for seq in train_A_padded]), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6baf8f95-faee-4bdb-a584-8569c20d93be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "119/119 [==============================] - 143s 1s/step - loss: 2.2243 - acc: 0.7863 - val_loss: 1.5586 - val_acc: 0.8207\n",
      "Epoch 2/10\n",
      "119/119 [==============================] - 140s 1s/step - loss: 1.4067 - acc: 0.8311 - val_loss: 1.4364 - val_acc: 0.8333\n",
      "Epoch 3/10\n",
      "119/119 [==============================] - 142s 1s/step - loss: 1.3165 - acc: 0.8328 - val_loss: 1.4172 - val_acc: 0.8337\n",
      "Epoch 4/10\n",
      "119/119 [==============================] - 165s 1s/step - loss: 1.2696 - acc: 0.8344 - val_loss: 1.4113 - val_acc: 0.8357\n",
      "Epoch 5/10\n",
      "119/119 [==============================] - 171s 1s/step - loss: 1.2329 - acc: 0.8369 - val_loss: 1.4102 - val_acc: 0.8330\n",
      "Epoch 6/10\n",
      "119/119 [==============================] - 175s 1s/step - loss: 1.1960 - acc: 0.8387 - val_loss: 1.4064 - val_acc: 0.8343\n",
      "Epoch 7/10\n",
      "119/119 [==============================] - 157s 1s/step - loss: 1.1579 - acc: 0.8410 - val_loss: 1.4048 - val_acc: 0.8350\n",
      "Epoch 8/10\n",
      "119/119 [==============================] - 154s 1s/step - loss: 1.1160 - acc: 0.8432 - val_loss: 1.3999 - val_acc: 0.8368\n",
      "Epoch 9/10\n",
      "119/119 [==============================] - 155s 1s/step - loss: 1.0738 - acc: 0.8459 - val_loss: 1.3977 - val_acc: 0.8366\n",
      "Epoch 10/10\n",
      "119/119 [==============================] - 141s 1s/step - loss: 1.0282 - acc: 0.8489 - val_loss: 1.3957 - val_acc: 0.8381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2fa3ac250>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([train_Q_padded, train_decoder_input_sequences], train_decoder_target_sequences, batch_size=64, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3f144bda-59cb-4b29-9cb5-13906691a604",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9e313eeb-a9fd-496c-a155-29cbf158969d",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(units,))\n",
    "decoder_state_input_c = Input(shape=(units,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_inputs_single = Input(shape=(1,))\n",
    "dec_emb2 = Embedding(vocab_size, embedding_dim)(decoder_inputs_single)\n",
    "decoder_outputs2, state_h2, state_c2 = LSTM(units, return_sequences=True, return_state=True)(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = Dense(vocab_size, activation='softmax')(decoder_outputs2)\n",
    "\n",
    "decoder_model = Model([decoder_inputs_single] + decoder_states_inputs, [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "45952ce6-4ac3-43fd-bbfd-415b9d85b6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = tokenizer.word_index['<start>']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = tokenizer.index_word[sampled_token_index]\n",
    "\n",
    "        decoded_sentence += ' ' + sampled_char\n",
    "\n",
    "        if sampled_char == '<end>' or len(decoded_sentence) > max_seq_length:\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence.replace('<start>', '').replace('<end>', '').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85762385-fd35-473f-b7b6-d58155914707",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"안녕하세요\"\n",
    "input_seq = preprocess_sentence(user_input)\n",
    "input_seq = tokenizer.texts_to_sequences([input_seq])\n",
    "input_seq = pad_sequences(input_seq, maxlen=max_len, padding='post')\n",
    "response = decode_sequence(input_seq)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "87998017-e4ac-4dfd-8df4-a6343e873297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "-\n",
      "질문: 죽을거 같네\n",
      "답변: 혼란스러워 혼란스러워 혼란스러워 혼란스러워\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "-\n",
      "질문: 내일 시험이야\n",
      "답변: 혼란스러워 혼란스러워 혼란스러워 혼란스러워\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "-\n",
      "질문: 정말내 자신이 싫다\n",
      "답변: 혼란스러워 혼란스러워 혼란스러워 혼란스러워\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "질문: 이별후 네달째\n",
      "답변: 혼란스러워 기다리지마세요 기다리지마세요 혼란스러워\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "-\n",
      "질문: 쌍커풀 해볼까\n",
      "답변: 혼란스러워 혼란스러워 혼란스러워 혼란스러워\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "-\n",
      "질문: 내 생각 하나만 바꾸면 편할텐데\n",
      "답변: 어쨌든 기념일에 어쨌든 다가오니까 다가오니까\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "-\n",
      "질문: 어떻게 살아가야 할까\n",
      "답변: 기다리지마세요 기다리지마세요 기다리지마세요\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "-\n",
      "질문: 발 아파\n",
      "답변: 혼란스러워 혼란스러워 혼란스러워 혼란스러워\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "-\n",
      "질문: 썸 타는 것도 귀찮아\n",
      "답변: 혼란스러워 혼란스러워 혼란스러워 혼란스러워\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "-\n",
      "질문: 좋아하는 애랑 전화하면\n",
      "답변: 혼란스러워 기다리지마세요 기다리지마세요 혼란스러워\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(10):\n",
    "    input_seq = test_Q_padded[seq_index:seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('질문:', test_Q[seq_index])\n",
    "    print('답변:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d61668-08e8-439e-8ac4-3f271e2ac612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3b565c-bbb2-42f8-a5c9-068a166e0806",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
