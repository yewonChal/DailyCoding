{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9c44ec9-ca71-4ffe-8f05-e5ff0421a5d4",
   "metadata": {},
   "source": [
    "# RNN(Recurrent Neural Network)\n",
    "- 문장과 같은 문자 데이터의 경우, 여러 개의 연관성이 깊은 Token들로 분할되어 표현된다.\n",
    "- 즉, 문장을 Input이나 Output으로 사용할 경우, 한 개의 벡터가 아닌 다수의 벡터의 형태로 사용해야 한다.\n",
    "- 형태\n",
    "    - Many-to-One : 댓글의 악플 가능성 정도를 측정하는 Sentence Classification\n",
    "    - One-to-Many : 사진 속 내용을 설명하는 글을 만들어 내는 Image Captioning\n",
    "    - Many-to-Many (token-by-token) : 문장의 모든 token에 대한 품사를 예측하는 Pos Tagging\n",
    "    - Many-to-Many (Encoder-Decoder) : 입력 문장을 다른 언어의 문장으로 번역해주는 Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c83854-ee7c-4cdf-bb72-7be3a04b1bee",
   "metadata": {},
   "source": [
    "# 장단기 메모리(Long Short-Term Memory) LSTM\n",
    "- 입력 게이트, 망각 게이트, 출력 게이트\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf89e63e-cbf3-4d78-9bf1-d673ec753fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_10 (SimpleRNN)   (None, 3)                 42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42 (168.00 Byte)\n",
      "Trainable params: 42 (168.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(3, input_shape=(2, 10))) # input_shape - 각 시퀸스의 길이(timesteps : 2), 각 시퀸스 피처수(input_dim : 10)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "404488b3-4c9b-4500-8a9f-629f2aab6405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_11 (SimpleRNN)   (8, 3)                    42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42 (168.00 Byte)\n",
      "Trainable params: 42 (168.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(3, batch_input_shape=(8, 2, 10))) # batch_size : 8\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22b8b6c9-47bf-43e4-922b-f9296a4c4076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_12 (SimpleRNN)   (8, 2, 3)                 42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42 (168.00 Byte)\n",
      "Trainable params: 42 (168.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# return_sequences : 각 타입 스택에 대해 시퀀스를 반환(batch_size, timesteps, units)\n",
    "model.add(SimpleRNN(3, batch_input_shape=(8, 2, 10), return_sequences=True)) # False는 마지막 타입스탭 출력만 반환\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d3f8c6f-4fad-494a-9cc1-02d904b934bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "초기 입력 :  [[0.83244596 0.97317203 0.96632453 0.96580037]\n",
      " [0.61539427 0.31099811 0.11296515 0.88155465]\n",
      " [0.13377058 0.14448534 0.7984165  0.50894758]\n",
      " [0.62448034 0.49997953 0.21231498 0.62609543]\n",
      " [0.9264382  0.19129316 0.17460837 0.11642955]\n",
      " [0.42417816 0.96678961 0.07221818 0.48438649]\n",
      " [0.10328317 0.25681741 0.77132073 0.70348754]\n",
      " [0.92306642 0.80156061 0.16796697 0.75018003]\n",
      " [0.66968235 0.53471724 0.3872255  0.31862822]\n",
      " [0.74132204 0.21320109 0.37134942 0.40683184]]\n",
      "초기 은닉 상태 :  [0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "timesteps = 10\n",
    "input_dim = 4\n",
    "hidden_units = 8\n",
    "\n",
    "inputs = np.random.random((timesteps, input_dim)) # 입력\n",
    "\n",
    "hidden_state_t = np.zeros((hidden_units, )) # 초기 hidden state 0 초기화\n",
    "\n",
    "print('초기 입력 : ', inputs)\n",
    "print('초기 은닉 상태 : ', hidden_state_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b77169f7-8b9f-4ef7-bc80-25e8854ea2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가중치 Wx의 크기(shape) : (8, 4)\n",
      "가중치 Wh의 크기(shape) : (8, 8)\n",
      "편향의 크기 : (8,)\n"
     ]
    }
   ],
   "source": [
    "Wx = np.random.random((hidden_units, input_dim)) # 입력에 대한 가중치\n",
    "Wh = np.random.random((hidden_units, hidden_units)) # 은닉 상태에 대한 가중치\n",
    "b = np.random.random((hidden_units,)) # 편향 bias\n",
    "\n",
    "print('가중치 Wx의 크기(shape) :', np.shape(Wx))\n",
    "print('가중치 Wh의 크기(shape) :', np.shape(Wh))\n",
    "print('편향의 크기 :', np.shape(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15fabe9a-22c7-48ba-a359-fcafb20072f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_hidden_states = []\n",
    "\n",
    "for input_t in inputs:\n",
    "    output_t = np.tanh(np.dot(Wx, input_t) + np.dot(Wh, hidden_state_t) + b)\n",
    "\n",
    "    total_hidden_states.append(list(output_t))\n",
    "    hidden_state_t = output_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d097380c-43c2-4384-880a-9112110a8eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99057473 0.96683902 0.99020053 0.99798093 0.95961964 0.99150509\n",
      "  0.99608987 0.98125777]\n",
      " [0.99980158 0.99998537 0.99998825 0.99998421 0.99993248 0.99999858\n",
      "  0.99998302 0.99970768]\n",
      " [0.99965459 0.99997954 0.99996549 0.99998439 0.9999151  0.99999775\n",
      "  0.99994692 0.99985678]\n",
      " [0.99984306 0.99998238 0.99998872 0.99998738 0.99994025 0.99999879\n",
      "  0.99998169 0.99978348]\n",
      " [0.99975856 0.99996836 0.9999732  0.99996906 0.99986179 0.99999658\n",
      "  0.99994636 0.99973029]\n",
      " [0.99984072 0.99997243 0.99999154 0.9999866  0.9999502  0.99999891\n",
      "  0.99998386 0.99975859]\n",
      " [0.99973352 0.99998419 0.9999769  0.99998917 0.99993871 0.99999855\n",
      "  0.99996719 0.99986563]\n",
      " [0.99994378 0.99998797 0.99999542 0.99999506 0.99996887 0.99999954\n",
      "  0.99999297 0.99984421]\n",
      " [0.9998493  0.99997581 0.99998453 0.99998722 0.99993149 0.99999851\n",
      "  0.99997187 0.9998304 ]\n",
      " [0.99980578 0.9999796  0.99997947 0.99998312 0.99991012 0.99999801\n",
      "  0.99996534 0.9998024 ]]\n"
     ]
    }
   ],
   "source": [
    "total_hidden_states = np.stack(total_hidden_states, axis=0)\n",
    "print(total_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaa863a-afd3-4bcf-b73f-24639fe74c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DRNN (Deep Recurrent Neural Network)\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(hidden_units, unput_length=10, input_dim=5, return_sequences=True))\n",
    "model.add(SimpleRNN(hidden_units, return_sequences=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d90fb3d4-4e7d-44f3-8cf5-f2a337bc59c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 양방향 순환 신경망 (Bidirectional Recurrent Neural Network)\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "timesteps = 10\n",
    "input_dim = 5\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(SimpleRNN(hidden_units, return_sequences=True), input_shape=(timesteps, input_dim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62afcd10-9b21-4766-8c7d-92278262e12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(SimpleRNN(hidden_units, return_sequences=True), input_shape=(timesteps, input_dim)))\n",
    "model.add(Bidirectional(SimpleRNN(hidden_units, return_sequences=True)))\n",
    "model.add(Bidirectional(SimpleRNN(hidden_units, return_sequences=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f1172ea0-ca52-4a2d-8a84-5a1f65f331a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import SimpleRNN, LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21a7f29e-72e9-465a-9a7a-016e60660b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 5)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = [[[0.1, 4.2, 1.5, 1.1, 2.8], [1.0, 3.1, 2.5, 0.7, 1.1], [0.3, 2.1, 1.5, 2.1, 0.1], [2.2, 1.4, 0.5, 0.9, 1.1]]]\n",
    "train_X = np.array(train_X, dtype=np.float32)\n",
    "\n",
    "train_X.shape # batchsize = 1, timesteps = 4, input_dim = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab40a767-3aec-4687-9023-c598ffeee807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden state : [[-0.81710523  0.97442234  0.40002725]], shape : (1, 3)\n"
     ]
    }
   ],
   "source": [
    "rnn = SimpleRNN(3) # return_sequences = False\n",
    "\n",
    "hidden_state = rnn(train_X)\n",
    "\n",
    "print('hidden state : {}, shape : {}'.format(hidden_state, hidden_state.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5b320ae-71b5-4edc-bb5c-18209283050e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden state : [[[-0.6452802   0.9657079   0.45361212]\n",
      "  [ 0.661944   -0.11003119 -0.38735315]\n",
      "  [-0.92919374 -0.8862208  -0.68701094]\n",
      "  [-0.5185234   0.98335373 -0.66300523]]], shape : (1, 4, 3)\n"
     ]
    }
   ],
   "source": [
    "rnn = SimpleRNN(3, return_sequences=True) # return_sequences = False\n",
    "hidden_state = rnn(train_X)\n",
    "\n",
    "print('hidden state : {}, shape : {}'.format(hidden_state, hidden_state.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4e91cfef-adac-441f-bde8-e5783c1cf90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden state : [[-0.9729656  -0.942357    0.89137435]], shape : (1, 3)\n",
      "last hidden state : [[-0.9729656  -0.942357    0.89137435]], shape : (1, 3)\n"
     ]
    }
   ],
   "source": [
    "rnn = SimpleRNN(3, return_state=True)\n",
    "hidden_state, last_state = rnn(train_X)\n",
    "# hidden_state = rnn(train_X)\n",
    "# last_state = rnn(train_X)\n",
    "\n",
    "print('hidden state : {}, shape : {}'.format(hidden_state, hidden_state.shape))\n",
    "print('last hidden state : {}, shape : {}'.format(last_state, last_state.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e7989663-3a7a-4101-a422-3c36dbf1c9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden state : [[[-0.97486466  0.19422278 -0.9977707 ]\n",
      "  [-0.55663025  0.2638994  -0.38727406]\n",
      "  [-0.894755   -0.5181923  -0.9285156 ]\n",
      "  [ 0.9531567  -0.57312834 -0.91599023]]], shape : (1, 4, 3)\n",
      "last hidden state : [[ 0.9531567  -0.57312834 -0.91599023]], shape : (1, 3)\n"
     ]
    }
   ],
   "source": [
    "# return_sequences = True, return_state = True\n",
    "rnn = SimpleRNN(3, return_sequences=True, return_state=True)\n",
    "hidden_state, last_state = rnn(train_X)\n",
    "\n",
    "print('hidden state : {}, shape : {}'.format(hidden_state, hidden_state.shape))\n",
    "print('last hidden state : {}, shape : {}'.format(last_state, last_state.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d807cfe4-2dd3-4d04-b682-c8a51ecfede6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden state : [[-0.23971796 -0.19362903 -0.06029086]], shape : (1, 3)\n",
      "last hidden state : [[-0.23971796 -0.19362903 -0.06029086]], shape : (1, 3)\n",
      "last cell state : [[-2.101681  -1.1213248 -0.6812372]], shape : (1, 3)\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM(3, return_state = True)\n",
    "hidden_state, last_state, last_cell_state = lstm(train_X)\n",
    "\n",
    "print('hidden state : {}, shape : {}'.format(hidden_state, hidden_state.shape))\n",
    "print('last hidden state : {}, shape : {}'.format(last_state, last_state.shape))\n",
    "print('last cell state : {}, shape : {}'.format(last_cell_state, last_cell_state.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "14e0f258-b97d-447b-8170-b53b99ed797a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden state : [[[-0.07066065 -0.03245606 -0.20404486]\n",
      "  [-0.10595854 -0.00335045 -0.4643949 ]\n",
      "  [-0.22937365 -0.05235196 -0.5731826 ]\n",
      "  [-0.14736535  0.03584218 -0.58428687]]], shape : (1, 4, 3)\n",
      "last hidden state : [[-0.14736535  0.03584218 -0.58428687]], shape : (1, 3)\n",
      "last cell state : [[-0.23852706  0.12280073 -1.2636827 ]], shape : (1, 3)\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM(3, return_sequences=True, return_state=True)\n",
    "hidden_state, last_state, last_cell_state = lstm(train_X)\n",
    "\n",
    "print('hidden state : {}, shape : {}'.format(hidden_state, hidden_state.shape))\n",
    "print('last hidden state : {}, shape : {}'.format(last_state, last_state.shape))\n",
    "print('last cell state : {}, shape : {}'.format(last_cell_state, last_cell_state.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fd3f5a29-f773-4f14-9b94-c9615c7b1661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기화 작업\n",
    "k_init = tf.keras.initializers.Constant(value=0.1) # 커널 가중치\n",
    "b_init = tf.keras.initializers.Constant(value=1) # 편향\n",
    "r_init = tf.keras.initializers.Constant(value=0.1) # 순환 가중치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8272835e-3c97-4082-8ea5-ea906269db8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden state : [[0.8583817  0.8583817  0.8583817  0.89662635 0.89662635 0.89662635]], shape : (1, 6)\n",
      "forward state : [[0.8583817 0.8583817 0.8583817]], shape : (1, 3)\n",
      "backward state : [[0.89662635 0.89662635 0.89662635]], shape : (1, 3)\n",
      "tf.Tensor([[2.7335248 2.7335248 2.7335248]], shape=(1, 3), dtype=float32) (1, 3)\n",
      "tf.Tensor([[2.8326864 2.8326864 2.8326864]], shape=(1, 3), dtype=float32) (1, 3)\n"
     ]
    }
   ],
   "source": [
    "bilstm = Bidirectional(LSTM(3, return_sequences=False, return_state=True,\n",
    "                            kernel_initializer=k_init, bias_initializer=b_init, recurrent_initializer=r_init))\n",
    "\n",
    "hidden_states, forward_h, forward_c, backward_h, backward_c = bilstm(train_X)\n",
    "# forward_h : 순방향 LSTM의 마지막 은닉 상태, forword_c : 셀 상태\n",
    "# forward_c, forward_c : 역방향 LSTM의 마지막 은닉 상태, 셀 상태\n",
    "\n",
    "print('hidden state : {}, shape : {}'.format(hidden_states, hidden_states.shape))\n",
    "print('forward state : {}, shape : {}'.format(forward_h, forward_h.shape))\n",
    "print('backward state : {}, shape : {}'.format(backward_h, backward_h.shape))\n",
    "print(forward_c, forward_c.shape)\n",
    "print(backward_c, backward_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ea9363c9-daf6-422a-9466-a0eb5d03e467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden state : [[[0.60378623 0.60378623 0.60378623 0.89662635 0.89662635 0.89662635]\n",
      "  [0.8135507  0.8135507  0.8135507  0.86469495 0.86469495 0.86469495]\n",
      "  [0.8438271  0.8438271  0.8438271  0.7678819  0.7678819  0.7678819 ]\n",
      "  [0.8583817  0.8583817  0.8583817  0.53885394 0.53885394 0.53885394]]], shape : (1, 4, 6)\n",
      "forward state : [[0.8583817 0.8583817 0.8583817]], shape : (1, 3)\n",
      "backward state : [[0.89662635 0.89662635 0.89662635]], shape : (1, 3)\n"
     ]
    }
   ],
   "source": [
    "# return_sequences = True, return_state = True\n",
    "bilstm = Bidirectional(LSTM(3, return_sequences=True, return_state=True,\n",
    "                            kernel_initializer=k_init, bias_initializer=b_init, recurrent_initializer=r_init))\n",
    "\n",
    "hidden_states, forward_h, forward_c, backward_h, backward_c = bilstm(train_X)\n",
    "\n",
    "print('hidden state : {}, shape : {}'.format(hidden_states, hidden_states.shape))\n",
    "print('forward state : {}, shape : {}'.format(forward_h, forward_h.shape))\n",
    "print('backward state : {}, shape : {}'.format(backward_h, backward_h.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bd1a531d-0edc-43dd-9844-c3f1e32765b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f268ef9d-1ff5-40ee-bc3d-5485b2415bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''오늘 날씨가 정말 좋다.\n",
    "집 앞 공원에 사람들이 모여 있다.\n",
    "아이들이 놀이터에서 신나게 뛰어놀고 있다.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a44b0fbd-937c-416f-82a2-94ae4efc7831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사전 크기 :  15\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "print('사전 크기 : ', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fcce744a-1426-4211-bd42-3241f723722c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'있다': 1, '오늘': 2, '날씨가': 3, '정말': 4, '좋다': 5, '집': 6, '앞': 7, '공원에': 8, '사람들이': 9, '모여': 10, '아이들이': 11, '놀이터에서': 12, '신나게': 13, '뛰어놀고': 14}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "50071374-4140-4855-8fb4-59cb4e821f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 개수 :  12\n"
     ]
    }
   ],
   "source": [
    "sequences = list()\n",
    "\n",
    "for line in text.split('\\n'):\n",
    "    encoded = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(encoded)):\n",
    "        sequence = encoded[:i+1]\n",
    "        sequences.append(sequence)\n",
    "\n",
    "print('샘플 개수 : ', len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "28d77f12-435d-4026-a555-97624276f3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 3], [2, 3, 4], [2, 3, 4, 5], [6, 7], [6, 7, 8], [6, 7, 8, 9], [6, 7, 8, 9, 10], [6, 7, 8, 9, 10, 1], [11, 12], [11, 12, 13], [11, 12, 13, 14], [11, 12, 13, 14, 1]]\n"
     ]
    }
   ],
   "source": [
    "print(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1fdd19b4-cf40-47fb-ace7-bca7e7e7797f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대 길이 :  6\n"
     ]
    }
   ],
   "source": [
    "max_len = max(len(_) for _ in sequences)\n",
    "print('최대 길이 : ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "edc8ecd8-5dcd-4e31-80bc-70ce86e367a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d45f72e4-10de-4905-8332-48e82bb927b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  2  3]\n",
      " [ 0  0  0  2  3  4]\n",
      " [ 0  0  2  3  4  5]\n",
      " [ 0  0  0  0  6  7]\n",
      " [ 0  0  0  6  7  8]\n",
      " [ 0  0  6  7  8  9]\n",
      " [ 0  6  7  8  9 10]\n",
      " [ 6  7  8  9 10  1]\n",
      " [ 0  0  0  0 11 12]\n",
      " [ 0  0  0 11 12 13]\n",
      " [ 0  0 11 12 13 14]\n",
      " [ 0 11 12 13 14  1]]\n"
     ]
    }
   ],
   "source": [
    "print(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3956ac44-ab8a-4409-ae1d-6429129f4fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = np.array(sequences)\n",
    "X = sequences[:, :-1]\n",
    "y = sequences[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "70346100-ae24-4745-9cb9-72fc7e7faa52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  2]\n",
      " [ 0  0  0  2  3]\n",
      " [ 0  0  2  3  4]\n",
      " [ 0  0  0  0  6]\n",
      " [ 0  0  0  6  7]\n",
      " [ 0  0  6  7  8]\n",
      " [ 0  6  7  8  9]\n",
      " [ 6  7  8  9 10]\n",
      " [ 0  0  0  0 11]\n",
      " [ 0  0  0 11 12]\n",
      " [ 0  0 11 12 13]\n",
      " [ 0 11 12 13 14]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2f1cf5b1-8ddb-4760-880f-b6b8f914bc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  4  5  7  8  9 10  1 12 13 14  1]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "be6a35a6-eb40-48ef-a480-44a87dc78dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# 원핫인코딩\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a50405c7-3e48-46bc-83fa-6e8399813919",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "99140da3-4ca6-4ec9-854d-36f1bb0dc9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 - 0s - loss: 2.7071 - accuracy: 0.1667 - 456ms/epoch - 456ms/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 2.6955 - accuracy: 0.2500 - 3ms/epoch - 3ms/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 2.6840 - accuracy: 0.2500 - 2ms/epoch - 2ms/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 2.6726 - accuracy: 0.2500 - 3ms/epoch - 3ms/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 2.6613 - accuracy: 0.2500 - 2ms/epoch - 2ms/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 2.6498 - accuracy: 0.2500 - 2ms/epoch - 2ms/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 2.6383 - accuracy: 0.3333 - 3ms/epoch - 3ms/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 2.6266 - accuracy: 0.3333 - 3ms/epoch - 3ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 2.6147 - accuracy: 0.3333 - 3ms/epoch - 3ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 2.6025 - accuracy: 0.3333 - 3ms/epoch - 3ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 2.5900 - accuracy: 0.2500 - 3ms/epoch - 3ms/step\n",
      "Epoch 12/200\n",
      "1/1 - 0s - loss: 2.5771 - accuracy: 0.2500 - 3ms/epoch - 3ms/step\n",
      "Epoch 13/200\n",
      "1/1 - 0s - loss: 2.5639 - accuracy: 0.2500 - 3ms/epoch - 3ms/step\n",
      "Epoch 14/200\n",
      "1/1 - 0s - loss: 2.5502 - accuracy: 0.2500 - 2ms/epoch - 2ms/step\n",
      "Epoch 15/200\n",
      "1/1 - 0s - loss: 2.5361 - accuracy: 0.2500 - 3ms/epoch - 3ms/step\n",
      "Epoch 16/200\n",
      "1/1 - 0s - loss: 2.5216 - accuracy: 0.1667 - 3ms/epoch - 3ms/step\n",
      "Epoch 17/200\n",
      "1/1 - 0s - loss: 2.5065 - accuracy: 0.2500 - 4ms/epoch - 4ms/step\n",
      "Epoch 18/200\n",
      "1/1 - 0s - loss: 2.4909 - accuracy: 0.2500 - 3ms/epoch - 3ms/step\n",
      "Epoch 19/200\n",
      "1/1 - 0s - loss: 2.4748 - accuracy: 0.2500 - 3ms/epoch - 3ms/step\n",
      "Epoch 20/200\n",
      "1/1 - 0s - loss: 2.4582 - accuracy: 0.2500 - 2ms/epoch - 2ms/step\n",
      "Epoch 21/200\n",
      "1/1 - 0s - loss: 2.4412 - accuracy: 0.2500 - 3ms/epoch - 3ms/step\n",
      "Epoch 22/200\n",
      "1/1 - 0s - loss: 2.4236 - accuracy: 0.2500 - 3ms/epoch - 3ms/step\n",
      "Epoch 23/200\n",
      "1/1 - 0s - loss: 2.4056 - accuracy: 0.2500 - 2ms/epoch - 2ms/step\n",
      "Epoch 24/200\n",
      "1/1 - 0s - loss: 2.3872 - accuracy: 0.2500 - 3ms/epoch - 3ms/step\n",
      "Epoch 25/200\n",
      "1/1 - 0s - loss: 2.3684 - accuracy: 0.2500 - 3ms/epoch - 3ms/step\n",
      "Epoch 26/200\n",
      "1/1 - 0s - loss: 2.3492 - accuracy: 0.2500 - 2ms/epoch - 2ms/step\n",
      "Epoch 27/200\n",
      "1/1 - 0s - loss: 2.3297 - accuracy: 0.2500 - 3ms/epoch - 3ms/step\n",
      "Epoch 28/200\n",
      "1/1 - 0s - loss: 2.3099 - accuracy: 0.2500 - 2ms/epoch - 2ms/step\n",
      "Epoch 29/200\n",
      "1/1 - 0s - loss: 2.2897 - accuracy: 0.2500 - 2ms/epoch - 2ms/step\n",
      "Epoch 30/200\n",
      "1/1 - 0s - loss: 2.2693 - accuracy: 0.2500 - 3ms/epoch - 3ms/step\n",
      "Epoch 31/200\n",
      "1/1 - 0s - loss: 2.2485 - accuracy: 0.2500 - 2ms/epoch - 2ms/step\n",
      "Epoch 32/200\n",
      "1/1 - 0s - loss: 2.2273 - accuracy: 0.3333 - 2ms/epoch - 2ms/step\n",
      "Epoch 33/200\n",
      "1/1 - 0s - loss: 2.2057 - accuracy: 0.3333 - 2ms/epoch - 2ms/step\n",
      "Epoch 34/200\n",
      "1/1 - 0s - loss: 2.1837 - accuracy: 0.3333 - 2ms/epoch - 2ms/step\n",
      "Epoch 35/200\n",
      "1/1 - 0s - loss: 2.1611 - accuracy: 0.3333 - 2ms/epoch - 2ms/step\n",
      "Epoch 36/200\n",
      "1/1 - 0s - loss: 2.1380 - accuracy: 0.3333 - 3ms/epoch - 3ms/step\n",
      "Epoch 37/200\n",
      "1/1 - 0s - loss: 2.1143 - accuracy: 0.3333 - 3ms/epoch - 3ms/step\n",
      "Epoch 38/200\n",
      "1/1 - 0s - loss: 2.0902 - accuracy: 0.3333 - 4ms/epoch - 4ms/step\n",
      "Epoch 39/200\n",
      "1/1 - 0s - loss: 2.0655 - accuracy: 0.4167 - 4ms/epoch - 4ms/step\n",
      "Epoch 40/200\n",
      "1/1 - 0s - loss: 2.0405 - accuracy: 0.5000 - 4ms/epoch - 4ms/step\n",
      "Epoch 41/200\n",
      "1/1 - 0s - loss: 2.0152 - accuracy: 0.5833 - 4ms/epoch - 4ms/step\n",
      "Epoch 42/200\n",
      "1/1 - 0s - loss: 1.9896 - accuracy: 0.5833 - 4ms/epoch - 4ms/step\n",
      "Epoch 43/200\n",
      "1/1 - 0s - loss: 1.9640 - accuracy: 0.5833 - 4ms/epoch - 4ms/step\n",
      "Epoch 44/200\n",
      "1/1 - 0s - loss: 1.9383 - accuracy: 0.5833 - 4ms/epoch - 4ms/step\n",
      "Epoch 45/200\n",
      "1/1 - 0s - loss: 1.9126 - accuracy: 0.5833 - 6ms/epoch - 6ms/step\n",
      "Epoch 46/200\n",
      "1/1 - 0s - loss: 1.8868 - accuracy: 0.5833 - 5ms/epoch - 5ms/step\n",
      "Epoch 47/200\n",
      "1/1 - 0s - loss: 1.8611 - accuracy: 0.6667 - 17ms/epoch - 17ms/step\n",
      "Epoch 48/200\n",
      "1/1 - 0s - loss: 1.8352 - accuracy: 0.6667 - 10ms/epoch - 10ms/step\n",
      "Epoch 49/200\n",
      "1/1 - 0s - loss: 1.8093 - accuracy: 0.6667 - 25ms/epoch - 25ms/step\n",
      "Epoch 50/200\n",
      "1/1 - 0s - loss: 1.7834 - accuracy: 0.6667 - 15ms/epoch - 15ms/step\n",
      "Epoch 51/200\n",
      "1/1 - 0s - loss: 1.7574 - accuracy: 0.7500 - 51ms/epoch - 51ms/step\n",
      "Epoch 52/200\n",
      "1/1 - 0s - loss: 1.7316 - accuracy: 0.7500 - 30ms/epoch - 30ms/step\n",
      "Epoch 53/200\n",
      "1/1 - 0s - loss: 1.7059 - accuracy: 0.7500 - 41ms/epoch - 41ms/step\n",
      "Epoch 54/200\n",
      "1/1 - 0s - loss: 1.6804 - accuracy: 0.7500 - 15ms/epoch - 15ms/step\n",
      "Epoch 55/200\n",
      "1/1 - 0s - loss: 1.6553 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "Epoch 56/200\n",
      "1/1 - 0s - loss: 1.6304 - accuracy: 0.7500 - 23ms/epoch - 23ms/step\n",
      "Epoch 57/200\n",
      "1/1 - 0s - loss: 1.6057 - accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "Epoch 58/200\n",
      "1/1 - 0s - loss: 1.5813 - accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
      "Epoch 59/200\n",
      "1/1 - 0s - loss: 1.5571 - accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
      "Epoch 60/200\n",
      "1/1 - 0s - loss: 1.5332 - accuracy: 0.7500 - 18ms/epoch - 18ms/step\n",
      "Epoch 61/200\n",
      "1/1 - 0s - loss: 1.5094 - accuracy: 0.8333 - 9ms/epoch - 9ms/step\n",
      "Epoch 62/200\n",
      "1/1 - 0s - loss: 1.4859 - accuracy: 0.9167 - 19ms/epoch - 19ms/step\n",
      "Epoch 63/200\n",
      "1/1 - 0s - loss: 1.4626 - accuracy: 0.9167 - 11ms/epoch - 11ms/step\n",
      "Epoch 64/200\n",
      "1/1 - 0s - loss: 1.4397 - accuracy: 0.9167 - 8ms/epoch - 8ms/step\n",
      "Epoch 65/200\n",
      "1/1 - 0s - loss: 1.4170 - accuracy: 0.9167 - 8ms/epoch - 8ms/step\n",
      "Epoch 66/200\n",
      "1/1 - 0s - loss: 1.3945 - accuracy: 0.9167 - 12ms/epoch - 12ms/step\n",
      "Epoch 67/200\n",
      "1/1 - 0s - loss: 1.3722 - accuracy: 0.9167 - 10ms/epoch - 10ms/step\n",
      "Epoch 68/200\n",
      "1/1 - 0s - loss: 1.3501 - accuracy: 0.9167 - 10ms/epoch - 10ms/step\n",
      "Epoch 69/200\n",
      "1/1 - 0s - loss: 1.3282 - accuracy: 0.9167 - 12ms/epoch - 12ms/step\n",
      "Epoch 70/200\n",
      "1/1 - 0s - loss: 1.3065 - accuracy: 0.9167 - 18ms/epoch - 18ms/step\n",
      "Epoch 71/200\n",
      "1/1 - 0s - loss: 1.2850 - accuracy: 0.9167 - 5ms/epoch - 5ms/step\n",
      "Epoch 72/200\n",
      "1/1 - 0s - loss: 1.2638 - accuracy: 0.9167 - 10ms/epoch - 10ms/step\n",
      "Epoch 73/200\n",
      "1/1 - 0s - loss: 1.2427 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "Epoch 74/200\n",
      "1/1 - 0s - loss: 1.2218 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "Epoch 75/200\n",
      "1/1 - 0s - loss: 1.2011 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "Epoch 76/200\n",
      "1/1 - 0s - loss: 1.1806 - accuracy: 1.0000 - 24ms/epoch - 24ms/step\n",
      "Epoch 77/200\n",
      "1/1 - 0s - loss: 1.1602 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 78/200\n",
      "1/1 - 0s - loss: 1.1401 - accuracy: 1.0000 - 25ms/epoch - 25ms/step\n",
      "Epoch 79/200\n",
      "1/1 - 0s - loss: 1.1201 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "Epoch 80/200\n",
      "1/1 - 0s - loss: 1.1003 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "Epoch 81/200\n",
      "1/1 - 0s - loss: 1.0808 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "Epoch 82/200\n",
      "1/1 - 0s - loss: 1.0614 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "Epoch 83/200\n",
      "1/1 - 0s - loss: 1.0422 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 84/200\n",
      "1/1 - 0s - loss: 1.0233 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 85/200\n",
      "1/1 - 0s - loss: 1.0046 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 86/200\n",
      "1/1 - 0s - loss: 0.9861 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 87/200\n",
      "1/1 - 0s - loss: 0.9679 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 88/200\n",
      "1/1 - 0s - loss: 0.9499 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "Epoch 89/200\n",
      "1/1 - 0s - loss: 0.9322 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 90/200\n",
      "1/1 - 0s - loss: 0.9147 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "Epoch 91/200\n",
      "1/1 - 0s - loss: 0.8975 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 92/200\n",
      "1/1 - 0s - loss: 0.8805 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "Epoch 93/200\n",
      "1/1 - 0s - loss: 0.8638 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 94/200\n",
      "1/1 - 0s - loss: 0.8473 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "Epoch 95/200\n",
      "1/1 - 0s - loss: 0.8311 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 96/200\n",
      "1/1 - 0s - loss: 0.8151 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "Epoch 97/200\n",
      "1/1 - 0s - loss: 0.7994 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "Epoch 98/200\n",
      "1/1 - 0s - loss: 0.7839 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 99/200\n",
      "1/1 - 0s - loss: 0.7687 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "Epoch 100/200\n",
      "1/1 - 0s - loss: 0.7537 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 101/200\n",
      "1/1 - 0s - loss: 0.7389 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "Epoch 102/200\n",
      "1/1 - 0s - loss: 0.7244 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "Epoch 103/200\n",
      "1/1 - 0s - loss: 0.7101 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 104/200\n",
      "1/1 - 0s - loss: 0.6960 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
      "Epoch 105/200\n",
      "1/1 - 0s - loss: 0.6821 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "Epoch 106/200\n",
      "1/1 - 0s - loss: 0.6684 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
      "Epoch 107/200\n",
      "1/1 - 0s - loss: 0.6550 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 108/200\n",
      "1/1 - 0s - loss: 0.6418 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 109/200\n",
      "1/1 - 0s - loss: 0.6288 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "Epoch 110/200\n",
      "1/1 - 0s - loss: 0.6160 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 111/200\n",
      "1/1 - 0s - loss: 0.6034 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "Epoch 112/200\n",
      "1/1 - 0s - loss: 0.5910 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 113/200\n",
      "1/1 - 0s - loss: 0.5789 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
      "Epoch 114/200\n",
      "1/1 - 0s - loss: 0.5669 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "Epoch 115/200\n",
      "1/1 - 0s - loss: 0.5552 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 116/200\n",
      "1/1 - 0s - loss: 0.5436 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "Epoch 117/200\n",
      "1/1 - 0s - loss: 0.5323 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "Epoch 118/200\n",
      "1/1 - 0s - loss: 0.5212 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 119/200\n",
      "1/1 - 0s - loss: 0.5102 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "Epoch 120/200\n",
      "1/1 - 0s - loss: 0.4995 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "Epoch 121/200\n",
      "1/1 - 0s - loss: 0.4890 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 122/200\n",
      "1/1 - 0s - loss: 0.4787 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 123/200\n",
      "1/1 - 0s - loss: 0.4686 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "Epoch 124/200\n",
      "1/1 - 0s - loss: 0.4587 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 125/200\n",
      "1/1 - 0s - loss: 0.4491 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 126/200\n",
      "1/1 - 0s - loss: 0.4396 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 127/200\n",
      "1/1 - 0s - loss: 0.4303 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "Epoch 128/200\n",
      "1/1 - 0s - loss: 0.4212 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 129/200\n",
      "1/1 - 0s - loss: 0.4124 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 130/200\n",
      "1/1 - 0s - loss: 0.4037 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 131/200\n",
      "1/1 - 0s - loss: 0.3952 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 132/200\n",
      "1/1 - 0s - loss: 0.3869 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "Epoch 133/200\n",
      "1/1 - 0s - loss: 0.3788 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "Epoch 134/200\n",
      "1/1 - 0s - loss: 0.3709 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "Epoch 135/200\n",
      "1/1 - 0s - loss: 0.3632 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 136/200\n",
      "1/1 - 0s - loss: 0.3557 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 137/200\n",
      "1/1 - 0s - loss: 0.3483 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 138/200\n",
      "1/1 - 0s - loss: 0.3411 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 139/200\n",
      "1/1 - 0s - loss: 0.3341 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 140/200\n",
      "1/1 - 0s - loss: 0.3273 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 141/200\n",
      "1/1 - 0s - loss: 0.3207 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 142/200\n",
      "1/1 - 0s - loss: 0.3142 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "Epoch 143/200\n",
      "1/1 - 0s - loss: 0.3078 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "Epoch 144/200\n",
      "1/1 - 0s - loss: 0.3017 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 145/200\n",
      "1/1 - 0s - loss: 0.2957 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "Epoch 146/200\n",
      "1/1 - 0s - loss: 0.2898 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 147/200\n",
      "1/1 - 0s - loss: 0.2841 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 148/200\n",
      "1/1 - 0s - loss: 0.2785 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 149/200\n",
      "1/1 - 0s - loss: 0.2731 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 150/200\n",
      "1/1 - 0s - loss: 0.2678 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 151/200\n",
      "1/1 - 0s - loss: 0.2626 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 152/200\n",
      "1/1 - 0s - loss: 0.2576 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 153/200\n",
      "1/1 - 0s - loss: 0.2527 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n",
      "Epoch 154/200\n",
      "1/1 - 0s - loss: 0.2479 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 155/200\n",
      "1/1 - 0s - loss: 0.2432 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 156/200\n",
      "1/1 - 0s - loss: 0.2387 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 157/200\n",
      "1/1 - 0s - loss: 0.2342 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 158/200\n",
      "1/1 - 0s - loss: 0.2299 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "Epoch 159/200\n",
      "1/1 - 0s - loss: 0.2257 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 160/200\n",
      "1/1 - 0s - loss: 0.2215 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 161/200\n",
      "1/1 - 0s - loss: 0.2175 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 162/200\n",
      "1/1 - 0s - loss: 0.2136 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 163/200\n",
      "1/1 - 0s - loss: 0.2098 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 164/200\n",
      "1/1 - 0s - loss: 0.2060 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 165/200\n",
      "1/1 - 0s - loss: 0.2024 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 166/200\n",
      "1/1 - 0s - loss: 0.1988 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 167/200\n",
      "1/1 - 0s - loss: 0.1953 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 168/200\n",
      "1/1 - 0s - loss: 0.1919 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 169/200\n",
      "1/1 - 0s - loss: 0.1886 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 170/200\n",
      "1/1 - 0s - loss: 0.1853 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 171/200\n",
      "1/1 - 0s - loss: 0.1821 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "Epoch 172/200\n",
      "1/1 - 0s - loss: 0.1790 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 173/200\n",
      "1/1 - 0s - loss: 0.1760 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
      "Epoch 174/200\n",
      "1/1 - 0s - loss: 0.1730 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 175/200\n",
      "1/1 - 0s - loss: 0.1701 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 176/200\n",
      "1/1 - 0s - loss: 0.1673 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "Epoch 177/200\n",
      "1/1 - 0s - loss: 0.1645 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "Epoch 178/200\n",
      "1/1 - 0s - loss: 0.1618 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 179/200\n",
      "1/1 - 0s - loss: 0.1591 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 180/200\n",
      "1/1 - 0s - loss: 0.1565 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 181/200\n",
      "1/1 - 0s - loss: 0.1540 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "Epoch 182/200\n",
      "1/1 - 0s - loss: 0.1515 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 183/200\n",
      "1/1 - 0s - loss: 0.1490 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 184/200\n",
      "1/1 - 0s - loss: 0.1466 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 185/200\n",
      "1/1 - 0s - loss: 0.1443 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "Epoch 186/200\n",
      "1/1 - 0s - loss: 0.1420 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 187/200\n",
      "1/1 - 0s - loss: 0.1398 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 188/200\n",
      "1/1 - 0s - loss: 0.1376 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 189/200\n",
      "1/1 - 0s - loss: 0.1354 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "Epoch 190/200\n",
      "1/1 - 0s - loss: 0.1333 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
      "Epoch 191/200\n",
      "1/1 - 0s - loss: 0.1312 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
      "Epoch 192/200\n",
      "1/1 - 0s - loss: 0.1292 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
      "Epoch 193/200\n",
      "1/1 - 0s - loss: 0.1272 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 194/200\n",
      "1/1 - 0s - loss: 0.1253 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 195/200\n",
      "1/1 - 0s - loss: 0.1234 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "Epoch 196/200\n",
      "1/1 - 0s - loss: 0.1215 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "Epoch 197/200\n",
      "1/1 - 0s - loss: 0.1197 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
      "Epoch 198/200\n",
      "1/1 - 0s - loss: 0.1179 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
      "Epoch 199/200\n",
      "1/1 - 0s - loss: 0.1161 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
      "Epoch 200/200\n",
      "1/1 - 0s - loss: 0.1144 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28c5ee260>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 10\n",
    "hidden_units = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(SimpleRNN(hidden_units))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=200, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "28ebda58-4e79-49e3-a0c0-940f135e5763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(model, tokenizer, current_word, n):\n",
    "    init_word = current_word\n",
    "    sentence = ''\n",
    "\n",
    "    for _ in range(n):\n",
    "        # 현재 단어에 대한 인코딩 및 패딩\n",
    "        encoded = tokenizer.texts_to_sequences([current_word])[0]\n",
    "        encoded = pad_sequences([encoded], maxlen=5, padding='pre')\n",
    "\n",
    "        # 현재 단어에 대한 예측\n",
    "        result = model.predict(encoded, verbose=0)\n",
    "        result = np.argmax(result, axis=1)\n",
    "\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == result:\n",
    "                break\n",
    "\n",
    "        current_word = current_word + ' ' + word\n",
    "\n",
    "        sentence = sentence + ' ' + word\n",
    "\n",
    "    sentence = init_word + sentence\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "db8b3986-23a0-4cd4-80af-05463d872418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오늘 날씨가 정말 좋다\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, tokenizer, '오늘', 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "154cdbf4-1791-4614-9ebe-b4d4ee3de17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "집 앞 공원에 사람들이 모여 있다\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, tokenizer, '집', 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "86310c18-f87b-42b3-bf61-bfee1e487c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아이들이 놀이터에서 신나게 뛰어놀고 있다\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, tokenizer, '아이들이', 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fd4bf35a-b0db-4d9a-ac05-afdad7ade389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "거북이 놀이터에서 앞 놀이터에서\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, tokenizer, '거북이', 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "56f3fd45-3972-43c8-a82b-1d4b69a09b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "빵 놀이터에서 앞 놀이터에서 신나게 뛰어놀고 있다 사람들이 모여 있다 사람들이\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, tokenizer, '빵', 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f282e62-1b9d-4646-b307-cbffddcdbe0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
