{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64552786-663f-41b7-8eb3-f3a4a93c4848",
   "metadata": {},
   "source": [
    "# 잔차 블록(Residual Block)\n",
    ": 신경망의 깊이를 증가시켜주면서 학습 성능을 향상시킨다.(ResNet(잔차 네트워크)에서 사용되는 종류 중 하나)\n",
    "\n",
    "- 입력을 그대로 전달하는 지름길을 추가하여 신경망이 깊어질 수록 발생할 수 있는 기울기 소실 문제를 완화시킨다.\n",
    "- 입력 특징 맵과 합성곱 레이어, 스킵 연결(지름길), 출력으로 총 4가지의 형태를 갖춘다.(밑 코드 참고)\n",
    "- y = F(x) + x, ( F(x) : 합성곱 층을 지나온 변환 함수 )\n",
    "    - 입력 신호(x) : 원래 입력 데이터 또는 이진 잔차 블록의 출력\n",
    "    - 합성곱 레이어(첫 번째 줄) : 일반적으로 ReLU 활성화 함수\n",
    "    - 합성곱 레이어(두 번째 줄) ::\n",
    "    - 스킵 연결(지름길) : 입력 신호를 직접 더하는 연결\n",
    "    - 출력 신호 : 스킵 연결을 포함한 최종 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60e35120-09a0-4e6b-aecf-54d5070fb83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = keras.Input(shape=(32, 32, 3)) # 입력층(입력 이미지 세팅)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(inputs) # 첫 번째 합성곱 레이어\n",
    "residual = x # 현재 특징맵 residual에 저장\n",
    "x = layers.Conv2D(64, 3, activation='relu', padding='same')(x) # 두 번째 합성곱 레이어\n",
    "residual = layers.Conv2D(64, 1)(residual) # 입력 특징 맵 차원을 조정하기 위해 1*1 합성곱 레이어를 적용한다.\n",
    "x = layers.add([x, residual]) # 두번째 합성곱 레이어의 출력과 조정된 입력 특징맵을 더해서 잔파 연결을 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7be9edbc-7e7d-4c02-bfb6-0299fc64b3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "x = layers.Conv2D(32, 3, activation='relu')(inputs)\n",
    "residual = x\n",
    "x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D(2, padding='same')(x) # 풀링 크기 2*2\n",
    "residual = layers.Conv2D(64, 1, strides = 2)(residual) # 풀링 크기에 맞춰 strides 설정\n",
    "# 연결하기 전 사이즈 정도는 맞춰주자는 느낌\n",
    "x = layers.add([x, residual])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dfccfed-861c-4c44-9185-be7ef1e1fbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "x = layers.Rescaling(1./255)(inputs)\n",
    "\n",
    "def residual_block(x, filters, pooling=False):\n",
    "    residual = x # 입력 데이터를 잔차에 저장 \n",
    "    x = layers.Conv2D(filters, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.Conv2D(filters, 3, activation='relu', padding='same')(x) # 기본 히든층 생성\n",
    "\n",
    "    if pooling: # pooling이 True라면, MaxPooling <-> 채널 수를 '1'로 맞춰준다.\n",
    "        x = layers.MaxPooling2D(2, padding='same')(x)\n",
    "        residual = layers.Conv2D(filters, 1, strides=2)(residual)\n",
    "    elif filters != residual.shape[-1]: # 채널 수가 다르다면\n",
    "        residual = layers.Conv2D(filters, 1)(residual) # 채널 수 맞춤\n",
    "\n",
    "    x = layers.add([x, residual]) # 잔차연결\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9c77966-9c52-44ce-8599-933afcc9ed72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)       [(None, 32, 32, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " rescaling_2 (Rescaling)     (None, 32, 32, 3)            0         ['input_10[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)          (None, 32, 32, 32)           896       ['rescaling_2[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)          (None, 32, 32, 32)           9248      ['conv2d_40[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPoolin  (None, 16, 16, 32)           0         ['conv2d_41[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)          (None, 16, 16, 32)           128       ['rescaling_2[0][0]']         \n",
      "                                                                                                  \n",
      " add_12 (Add)                (None, 16, 16, 32)           0         ['max_pooling2d_8[0][0]',     \n",
      "                                                                     'conv2d_42[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)          (None, 16, 16, 64)           18496     ['add_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_43[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPoolin  (None, 8, 8, 64)             0         ['conv2d_44[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)          (None, 8, 8, 64)             2112      ['add_12[0][0]']              \n",
      "                                                                                                  \n",
      " add_13 (Add)                (None, 8, 8, 64)             0         ['max_pooling2d_9[0][0]',     \n",
      "                                                                     'conv2d_45[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)          (None, 8, 8, 128)            73856     ['add_13[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)          (None, 8, 8, 128)            147584    ['conv2d_46[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)          (None, 8, 8, 128)            8320      ['add_13[0][0]']              \n",
      "                                                                                                  \n",
      " add_14 (Add)                (None, 8, 8, 128)            0         ['conv2d_47[0][0]',           \n",
      "                                                                     'conv2d_48[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2  (None, 128)                  0         ['add_14[0][0]']              \n",
      "  (GlobalAveragePooling2D)                                                                        \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 1)                    129       ['global_average_pooling2d_2[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 297697 (1.14 MB)\n",
      "Trainable params: 297697 (1.14 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = residual_block(x, filters=32, pooling=True)\n",
    "x = residual_block(x, filters=64, pooling=True)\n",
    "x = residual_block(x, filters=128, pooling=False)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x) # 전역 평균 풀링 레이어를 통해 특징 맵의 차원을 1로 줄인다.\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x) \n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68fb8f09-626f-470e-a466-af469a1bf715",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=18uC7WTuEXKJDDxbj-Jq6EjzpFrgE7IAd\n",
      "From (redirected): https://drive.google.com/uc?id=18uC7WTuEXKJDDxbj-Jq6EjzpFrgE7IAd&confirm=t&uuid=12d8a496-a058-4e78-8986-03f4af328f37\n",
      "To: /Users/jeon-yewon/Desktop/데이터 분석 강의/부트캠프/8주차/06.17./dogs-vs-cats.zip\n",
      "100%|████████████████████████████████████████| 852M/852M [01:30<00:00, 9.46MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'dogs-vs-cats.zip'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "gdown.download(id='18uC7WTuEXKJDDxbj-Jq6EjzpFrgE7IAd', output='dogs-vs-cats.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23b76b35-f4e9-4743-ac2c-a6090798c5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('dogs-vs-cats.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall()\n",
    "\n",
    "with zipfile.ZipFile('train.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "778f7742-dbb6-4ffa-adf3-8b08faec7355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, pathlib\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "original_dir = pathlib.Path('train')\n",
    "new_base_dir = pathlib.Path('cats_vs_dags_small')\n",
    "\n",
    "def make_subset(subset_name, start_index, end_index):\n",
    "    for category in ('cat', 'dog'):\n",
    "        dir = new_base_dir / subset_name / category\n",
    "        if not dir.exists():\n",
    "            os.makedirs(dir)\n",
    "        fnames = [f'{category}.{i}.jpg' for i in range(start_index, end_index)]\n",
    "        for fname in fnames:\n",
    "            shutil.copyfile(src=original_dir / fname, dst = dir/fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e08fcd64-d861-4b6a-86b8-c1f6c1492db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_subset('train', start_index=0, end_index=1000)\n",
    "make_subset('validation', start_index=1000, end_index=1500)\n",
    "make_subset('test', start_index=1500, end_index=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2ec2636-5aaa-4d53-85fc-10372bbe7777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n",
      "Found 1000 files belonging to 2 classes.\n",
      "Found 2000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / 'train', \n",
    "    image_size = (180, 180),\n",
    "    batch_size = 32)\n",
    "\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / 'validation',\n",
    "    image_size = (180, 180),\n",
    "    batch_size = 32)\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / 'test',\n",
    "    image_size = (180, 180),\n",
    "    batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4916c75-5374-4170-8040-5ba1a952f033",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip('horizontal'),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.2),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec353df0-34d4-47c0-bcbb-6e56ff1b7a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "inputs = tf.keras.Input(shape=(180, 180, 3))\n",
    "x = data_augmentation(inputs)\n",
    "\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=5, use_bias=False)(x)\n",
    "\n",
    "for size in [32, 64, 128, 256, 512]:\n",
    "    residual = x\n",
    "\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.SeparableConv2D(size, 3, padding='same', use_bias=False)(x)\n",
    "\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.SeparableConv2D(size, 3, padding='same', use_bias=False)(x)\n",
    "\n",
    "    x = layers.MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "\n",
    "    residual = layers.Conv2D(size, 1, strides=2, padding='same', use_bias=False)(residual)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4102ba86-0b27-4f7c-99c4-489dac149783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "63/63 [==============================] - 174s 3s/step - loss: 0.7172 - accuracy: 0.5725 - val_loss: 0.7026 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 155s 2s/step - loss: 0.6594 - accuracy: 0.5990 - val_loss: 0.6964 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 155s 2s/step - loss: 0.6341 - accuracy: 0.6390 - val_loss: 0.7087 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 170s 3s/step - loss: 0.6271 - accuracy: 0.6585 - val_loss: 0.7097 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 276s 4s/step - loss: 0.6011 - accuracy: 0.6885 - val_loss: 0.8045 - val_accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 283s 4s/step - loss: 0.5807 - accuracy: 0.6965 - val_loss: 0.8330 - val_accuracy: 0.5020\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 283s 4s/step - loss: 0.5722 - accuracy: 0.7165 - val_loss: 0.8358 - val_accuracy: 0.5300\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 311s 5s/step - loss: 0.5508 - accuracy: 0.7290 - val_loss: 0.6944 - val_accuracy: 0.5600\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 302s 5s/step - loss: 0.5429 - accuracy: 0.7390 - val_loss: 0.8157 - val_accuracy: 0.5620\n",
      "Epoch 10/10\n",
      " 8/63 [==>...........................] - ETA: 4:12 - loss: 0.5000 - accuracy: 0.7773"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "history = model.fit(train_dataset, epochs=10, validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2edad2c-e4fd-4275-bb72-bb6d1a9c73a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(accuracy)+1)\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f853e3-1d88-4887-993b-2e279e01da4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, loss, 'bo', label='Training Accuracy')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f86a153-0124-430d-94c3-38bc12dc3d93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
