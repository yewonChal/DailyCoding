{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "725245a9-fc5f-4539-bd40-0a57833ef3ce",
   "metadata": {},
   "source": [
    "# Word2Vec\n",
    ": 단어를 벡터 공간으로 변환하는 자연어 처리 기법\n",
    "\n",
    "- 임베딩 : 단어를 고정된 크기의 실수 벡터로 변환\n",
    "\n",
    "- 분산표현 : 단어를 하나의 차원에서 표현하는 대신 여러 차원에서 분산적으로 표현한다.\n",
    "\n",
    "- ex) The Quick Brown Fox Jumps Over The Lazy Dog.\n",
    "\n",
    "1. CBOW : 주어진 문맥을 이용해서 중심단어를 예측하는 방법\n",
    "- 주어진 문장에서 fox를 예측한다.(다른 단어의 의미를 통해 fox의 의미 파악)\n",
    "\n",
    "2. Skip-gram' : 중심 단어를 통해 주변 단어를 예측하는 방법\n",
    "- fox를 통해 나머지 단어를 추측한다.(다른 하나하나 단어가 어떤 의미인지)\n",
    "\n",
    "=> 단어 벡터 초기화 -> 단어 벡터 업데이트(CBOW, Skip-gram) -> 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41e695a1-073c-4fcd-a105-ee9966d06312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "sentences = [\n",
    "    ['the', 'quick', 'brown', 'fox', 'jumps', 'over' ,'the', 'lazy', 'dog'],\n",
    "    ['I', 'love', 'natural', 'language', 'processing'],\n",
    "    ['All', 'we', 'have', 'is', 'now']\n",
    "]\n",
    "\n",
    "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "597e619a-9c04-40ed-a8b8-a96834223d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00713902,  0.00124103, -0.00717672, -0.00224462,  0.0037193 ,\n",
       "        0.00583312,  0.00119818,  0.00210273, -0.00411039,  0.00722533,\n",
       "       -0.00630704,  0.00464722, -0.00821997,  0.00203647, -0.00497705,\n",
       "       -0.00424769, -0.00310898,  0.00565521,  0.0057984 , -0.00497465,\n",
       "        0.00077333, -0.00849578,  0.00780981,  0.00925729, -0.00274233,\n",
       "        0.00080022,  0.00074665,  0.00547788, -0.00860608,  0.00058446,\n",
       "        0.00686942,  0.00223159,  0.00112468, -0.00932216,  0.00848237,\n",
       "       -0.00626413, -0.00299237,  0.00349379, -0.00077263,  0.00141129,\n",
       "        0.00178199, -0.0068289 , -0.00972481,  0.00904058,  0.00619805,\n",
       "       -0.00691293,  0.00340348,  0.00020606,  0.00475375, -0.00711994,\n",
       "        0.00402695,  0.00434743,  0.00995737, -0.00447374, -0.00138926,\n",
       "       -0.00731732, -0.00969783, -0.00908026, -0.00102275, -0.00650329,\n",
       "        0.00484973, -0.00616403,  0.00251919,  0.00073944, -0.00339215,\n",
       "       -0.00097922,  0.00997913,  0.00914589, -0.00446183,  0.00908303,\n",
       "       -0.00564176,  0.00593092, -0.00309722,  0.00343175,  0.00301723,\n",
       "        0.00690046, -0.00237388,  0.00877504,  0.00758943, -0.00954765,\n",
       "       -0.00800821, -0.0076379 ,  0.00292326, -0.00279472, -0.00692952,\n",
       "       -0.00812826,  0.00830918,  0.00199049, -0.00932802, -0.00479272,\n",
       "        0.00313674, -0.00471321,  0.00528084, -0.00423344,  0.0026418 ,\n",
       "       -0.00804569,  0.00620989,  0.00481889,  0.00078719,  0.00301345],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['fox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52e57250-d942-478a-aead-75396101c437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('processing', 0.25290459394454956),\n",
       " ('quick', 0.17018884420394897),\n",
       " ('language', 0.15016479790210724),\n",
       " ('jumps', 0.13887131214141846),\n",
       " ('have', 0.10852647572755814),\n",
       " ('over', 0.03476286679506302),\n",
       " ('we', 0.016065234318375587),\n",
       " ('is', 0.0044950623996555805),\n",
       " ('natural', -0.005896796938031912),\n",
       " ('the', -0.027750343084335327)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('fox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d5fce71-626d-40a9-804b-76700d4f4f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jeon-\n",
      "[nltk_data]     yewon/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from lxml import etree\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "nltk.download('punkt') # punkt 토크나이저 다운로드(문장 경계 인식)\n",
    "\n",
    "targetXML = open('ted_en-20160408.xml', 'r', encoding='UTF8')\n",
    "target_text = etree.parse(targetXML) # etree 라이브러리로 파싱\n",
    "\n",
    "parse_text = '\\n'.join(target_text.xpath('//content/text()')) # <content> 태그 사이의 텍스트들을 추출\n",
    "\n",
    "content_text = re.sub(r'\\([^)]*\\)', '', parse_text) # 정규표현식 : () 괄호로 묶인 내용 삭제\n",
    "sent_text = sent_tokenize(content_text) # 텍스트를 문장 단위로 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc9e4075-d48c-4092-a4d2-312097230389",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_text = []\n",
    "\n",
    "for string in sent_text:\n",
    "    tokens = re.sub(r'[^a-z0-9]+', ' ', string.lower()) # 구두점 제거, 소문자\n",
    "    normalized_text.append(tokens)\n",
    "\n",
    "result = [word_tokenize(sentence) for sentence in normalized_text] # 문장을 단어 단위로 토큰화 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49c893b3-088b-4805-82ae-d62778843f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new']\n"
     ]
    }
   ],
   "source": [
    "print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99553701-9371-47e2-9567-3a3e76cee99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플 수 :  273424\n"
     ]
    }
   ],
   "source": [
    "print('총 샘플 수 : ', len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04c9d39d-2bb2-4066-b9cc-916ba22f1317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# sentences : 학습에 사용할 문장 데이터\n",
    "# vector_size : 각 단어에 사용할 벡터 차원 수\n",
    "# window : 단어 예측 시 고려할 문맥의 크기\n",
    "# min_count : 최소 출현 횟수(희소 단어 제거)\n",
    "# workers : CPU 스레드 수 설정(몇 명이서 학습할 것인지)\n",
    "# sg : 학습 알고리즘(0 : CBOW, 1 : Skip-gram)\n",
    "model = Word2Vec(sentences=result, vector_size=100, window=5, min_count=5, workers=4, sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffa82716-ef5d-43e6-b92d-b45c841824ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('organizations', 0.8111226558685303), ('businesses', 0.7698550224304199), ('jobs', 0.7596983909606934), ('programs', 0.7462173104286194), ('farmers', 0.7396450638771057), ('institutions', 0.738227903842926), ('teams', 0.7358756065368652), ('groups', 0.7033401727676392), ('workers', 0.7012938857078552), ('entrepreneurs', 0.6982468366622925)]\n"
     ]
    }
   ],
   "source": [
    "model_result = model.wv.most_similar('companies')\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "093060f5-3b5f-4935-9c86-9fe10af202c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=result, vector_size=100, window=5, min_count=5, workers=4, sg=0)\n",
    "model.wv.save_word2vec_format('eng_ted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eea7a68c-4746-420b-af49-16333eb44fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = KeyedVectors.load_word2vec_format('eng_ted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff5885dc-69a6-46ff-bd07-bdee0744d1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woman', 0.8355895280838013), ('guy', 0.7914246320724487), ('lady', 0.7593194842338562), ('boy', 0.7455564737319946), ('soldier', 0.7229838967323303), ('girl', 0.7186998724937439), ('gentleman', 0.7147846817970276), ('kid', 0.679377555847168), ('poet', 0.678987443447113), ('photographer', 0.6514443755149841)]\n"
     ]
    }
   ],
   "source": [
    "model_result = loaded_model.most_similar('man')\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "637c5c7d-8bb0-4f72-ba50-5c718df02db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ man과 유사한 단어 Top5 ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>woman</td>\n",
       "      <td>0.835590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>guy</td>\n",
       "      <td>0.791425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lady</td>\n",
       "      <td>0.759319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boy</td>\n",
       "      <td>0.745556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soldier</td>\n",
       "      <td>0.722984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word  Similarity\n",
       "0    woman    0.835590\n",
       "1      guy    0.791425\n",
       "2     lady    0.759319\n",
       "3      boy    0.745556\n",
       "4  soldier    0.722984"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 숙제 1) ted 데이터 GloVec로 유사 단어 예측(상위 5개)\n",
    "import pandas as pd\n",
    "\n",
    "similar_words = model.wv.most_similar('man', topn=5)\n",
    "similar_words_df = pd.DataFrame(similar_words, columns=['Word', 'Similarity'])\n",
    "print(\"[ man과 유사한 단어 Top5 ]\")\n",
    "similar_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908a424e-8e01-418e-b78f-3a0c5acc07fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GloVec 사용을 위해 파일 불러오기\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "embeddings_index = {}\n",
    "\n",
    "with open('glove.6B.100d.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        # print(line)\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.array(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(f'Found {len(embeddings_index)} word vectors.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9100f5c6-9516-43fe-933c-b90db79d42b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코사인 유사도를 이용하여 처리하는 방법\n",
    "from sklearn.metrics.pairwise import consine_similarity\n",
    "\n",
    "def find_similar_words(word, embeddings_index, top_n=5):\n",
    "    if word not in embeddings_index:\n",
    "        return []\n",
    "\n",
    "    word_vector = embedding_index[word].reshape(1, -1) # 위에서 만든 딕셔너리에 해당 단어에 대한 값(임베딩 벡터)을 2차원 배열로 변환\n",
    "    similarities = {}\n",
    "\n",
    "    for other_word, other_vector in embeddings_index.items():\n",
    "        if other_word != word:\n",
    "            similarity = cosine_similarity(word_vector, other_vector.reshape(1, -1))[0][0] # 현재 단어와 다른 모든 단어들의 코사인 유사도를 계산\n",
    "            # [0][0] : 유사도 점수\n",
    "            similarities[other_word] = similarity # 위에서 만든 딕셔너리에 방금 계산한 similarity값을 넣어준다.\n",
    "\n",
    "        similar_words = sorted(similatities.items(), key=lambda item: item[1], reverse=True)[:top_n]\n",
    "        return similar_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec8a123-d299-4bbe-b21f-e922bad29b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_word = 'companies'\n",
    "similar_words = find_similar_words(example_word, embeddings_index)\n",
    "print(f\"Words similar to '{example_word}':\")\n",
    "for word, score in similar_words:\n",
    "    print(f'{word} : {score:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bca63b-7483-46f3-bda2-f4a41bfe4a9b",
   "metadata": {},
   "source": [
    "# Word2Vec & GloVe : 단어 임베딩 기술\n",
    "1. 학습방식\n",
    "- Word2Vec : CBOW 또는 Skip-gram 모델을 사용하여 학습한다.\n",
    "- GLoVe : 단어 간 동시발생행렬을 사용하여 학습한다.\n",
    "\n",
    "2. 입력 데이터\n",
    "- Word2Vec : 문서 내 단어 순서를 고려하여 학습한다.\n",
    "- GLoVe : 전체에서 단어 간 동시 발생 정보를 활용하여 학습한다.\n",
    "\n",
    "3. 목표\n",
    "- Word2Vec : 주변 단어 예측\n",
    "- GloVe : 단어 간 상호관계 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c302f80d-f2fc-4cdb-a90a-931567cabfd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
