{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "139362e9-4b6c-4d23-a480-432bc2a90906",
   "metadata": {},
   "source": [
    "# 트랜스포머 아키텍처\n",
    ": 셀프 어텐션을 통해 문장의 맥락을 포착하는데 사용되는 기법(문장 속 모든 단어의 관련성과 맥락을 학습)\n",
    "\n",
    "### * 셀프 어텐션(Self-Attention)\n",
    ": 시퀸스의 각 단어가 다른 단어들과 어떻게 관련되어 있는지 계산하는 메커니즘\n",
    "1. 쿼리, 키, 값의 벡터를 생성(세 개의 벡터)\n",
    "2. 어텐션 스코어 : 각 단어의 쿼리 벡터와 모든 단어의 키 벡터를 곱한다.\n",
    "3. 소프트맥스 : 어텐션 스코어를 소프트맥스 함수에 통과시켜 가중치를 만든다.\n",
    "4. 어텐션 값 : 가중치를 값 벡터에 곱하여 가중합을 계산한다.\n",
    "    - 공식 : Attebtui(Q, K, V) = softmax(QK^T/루트dk)V 이런 느낌...?\n",
    "\n",
    "### * 인코더-디코더 구조\n",
    "- 인코더\n",
    "1. 입력 임베딩 : 입력된 각 단어를 특정 차원의 벡터로 변환한다.\n",
    "2. 포지셔널 인코딩 : 단어의 위치 정보를 추가하여 순서의 의미를 반영한다.\n",
    "3. 인코더 레이어 : 각 레이어는 셀프 어텐션과 피드포워드 네트워크로 이루어져 있다. ⭐️\n",
    "\n",
    "- 디코더\n",
    "1. 출력 임베딩 : 생성된 각 단어를 특정 차원의 벡터로 변환한다.\n",
    "2. 포지셔널 인코딩 : 위치정보 추가\n",
    "3. 디코더 레이어 : 각 레이어는 셀프 어텐션과 피드포워드 네트워크, 인코더-디코더 어텐션으로 이루어져 있다.⭐️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa7fb028-1cbf-4fde-99c7-f4fc8a647bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 files belonging to 2 classes.\n",
      "Found 5000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# 기존에 사용했던 데이터 들고오기\n",
    "import os, pathlib, shutil, random\n",
    "from tensorflow import keras\n",
    "\n",
    "batch_size = 32\n",
    "base_dir = pathlib.Path('aclImdb')\n",
    "val_dir = base_dir / 'va'\n",
    "train_dir = base_dir / 'train'\n",
    "\n",
    "# for category in ('neg', 'pos'):\n",
    "#     os.makedirs(val_dir / category)\n",
    "#     files = od.listdir(train_dir / category)\n",
    "#     random.Random(1337).shuffle(files)\n",
    "\n",
    "train_ds = keras.utils.text_dataset_from_directory(\n",
    "    'aclImdb/train', batch_size = batch_size)\n",
    "\n",
    "val_ds = keras.utils.text_dataset_from_directory(\n",
    "    'aclImdb/val', batch_size = batch_size)\n",
    "\n",
    "test_ds = keras.utils.text_dataset_from_directory(\n",
    "    'aclImdb/test', batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a781a8d1-f05c-4d5b-a58e-f40f080499f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_only_train_ds = train_ds.map(lambda x, y : x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42f568a9-d3cc-4307-b1c5-5643e7eac525",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "max_length = 600\n",
    "max_tokens = 20000\n",
    "\n",
    "text_vectorization = layers.TextVectorization(\n",
    "    max_tokens = max_tokens,\n",
    "    output_mode = 'int',\n",
    "    output_sequence_length = max_length,\n",
    ")\n",
    "\n",
    "text_vectorization.adapt(text_only_train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b75d52c4-9493-446a-991a-9d9d8dfa35ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_train_ds = train_ds.map(\n",
    "    lambda x, y : (text_vectorization(x), y),\n",
    "    num_parallel_calls = 4)\n",
    "\n",
    "int_val_ds = val_ds.map(\n",
    "    lambda x, y : (text_vectorization(x), y),\n",
    "    num_parallel_calls = 4)\n",
    "\n",
    "int_test_ds = test_ds.map(\n",
    "    lambda x, y : (text_vectorization(x), y),\n",
    "    num_parallel_calls = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95a7c53-1002-4f4d-8182-e9f6fc0a7e7e",
   "metadata": {},
   "source": [
    "# 멀티 헤드 어텐션 \n",
    ": 셀프 어텐션의 여러 헤드를 병렬로 사용하는 방식(각각 헤드가 다른 부분을 처리하여 다양한 표현을 학습할 수 있다.)\n",
    "\n",
    "- 다중 헤드 분할 : 입력을 여러 개의 서브스페이스로 분할한다.\n",
    "- 개발 어텐션 계산 : 각 서브스페이스에서 셀프 어텐션을 수행한다.\n",
    "- 병합 : 각 헤드의 출력을 병합하여 다음 레이어로 전달한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fec87e4e-1f47-437a-aa22-f51d218f7937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class TransformerEncoder(layers.Layer): # layer을 상속받아 Layer 처리 진행\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs): # 각 차원 수를 전달받아 처리한다.\n",
    "        super(TransformerEncoder, self).__init__(**kwargs) # 다중입력처리를 입력받아 부모에게 전달\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim) # multi\n",
    "        self.dense_proj = keras.Sequential( # 두 개의 dense 층으로 이루어진 모델 = 피드포워드 네트워크(신경망)\n",
    "        # 피드포워드 네트워크 : 정규화된 출력을 두 개의 밀집 레이어에 통과시킨다.\n",
    "            [layers.Dense(dense_dim, activation='relu'),\n",
    "             layers.Dense(embed_dim)]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization() # 정규화 층\n",
    "        self.layernorm_2 = layers.LayerNormalization() # 정규화 층\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask[:, tf.newaxis, :] # 차원 확장\n",
    "        attention_output = self.attention(inputs, inputs, attention_mask=mask) # 멀티헤드 어텐션 레이어의 출력(쿼리, 키, 값)\n",
    "        proj_input = self.layernorm_1(inputs + attention_output) # 입력과 어텐션을 더한 값(정규화 처리)\n",
    "        proj_output = self.dense_proj(proj_input) # 통과\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "    def get_config(self): # 구성요소 저장 함수\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "        'embed_dim' : self.embed_dim,\n",
    "        'num_heads' : self.num_heads,\n",
    "        'dense_dim' : self.dense_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# 트랜스포머 인코더 순서 : 멀티 헤드 셀프 어텐션 -> 잔차 연결 -> 정규화 -> 피드포워드 신경망 -> 잔차 연결 -> 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b7af98b-d604-4b96-9942-85c30cb1fd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, None, 256)         5120000   \n",
      "                                                                 \n",
      " transformer_encoder_1 (Tra  (None, None, 256)         543776    \n",
      " nsformerEncoder)                                                \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Gl  (None, 256)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5664033 (21.61 MB)\n",
      "Trainable params: 5664033 (21.61 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 분류 작업 진행\n",
    "vocab_size = 20000\n",
    "embed_dim = 256\n",
    "num_heads = 2\n",
    "dense_dim = 32\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype='int64')\n",
    "x = layers.Embedding(vocab_size, embed_dim)(inputs) # 임베딩 벡터 변환\n",
    "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x) # 트랜스포머 인코더\n",
    "x = layers.GlobalMaxPooling1D()(x) # 시퀀스 차원에서 최대풀링을 수행하여 고정 크기의 특징 벡터를 얻는다.\n",
    "x = layers.Dropout(0.5)(x)\n",
    "# 위 코드에서 써놓은 트랜스포머 인코더 순서를 모두 마친 후 x에 값 저장\n",
    "\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "98ca2c88-9ff4-4c86-8686-14915385c526",
   "metadata": {},
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint('transformer_encoder.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "model.fit(int_train_ds, validation_data = int_val_ds, epochs=10, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1e61dfb-b096-40ea-bdc5-869702df9741",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293/782 [==========>...................] - ETA: 23:54 - loss: 1.2959 - accuracy: 0.5076"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('transformer_encoder.h5', custom_objects={'TransformerEncoder' : TransformerEncoder})\n",
    "print(f'테스트 정확도 : {model.evaluate(int_test_ds)[1]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200217fa-7aa0-4c51-9818-69f03b74820e",
   "metadata": {},
   "source": [
    "# 위치 인코딩(Position Encoding)\n",
    ": 각 토큰의 위치 정보를 인코딩하여 입력에 추가하는 것(모델이 입력 시퀀스의 순서 정보를 학습)\n",
    "- 트랜스포머 모델은 순차적인 정보 처리를 위한 재귀적 구조가 존재하지 않는다.\n",
    "\n",
    "1. 고정 위치 인코딩(Fixed Position Encoding)\n",
    ": 계산이 간단하고 구현하기 쉽지만 입력 시퀀스의 길이가 고정되어야 한다.\n",
    "- sin()과 cos() 함수를 사용하여 각 토큰의 위치정보를 인코딩한다.\n",
    "- PE(pos, 2i) = sin(pos/10000^(2i/d_model))\n",
    "- PE(pos, 2i+1) = cos(pos/10000^(2i/d_model))\n",
    "\n",
    "2. 학습 가능한 위치 인코딩(Learned Position Encoding)\n",
    ": 입력 시퀀스의 길이는 제한이 없지만 별도의 학습과정이 필요하다.\n",
    "- 위치 정보를 학습 가능한 매개변수로 표현한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34e3552c-d3cc-4ac2-b2be-a4ee08169858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위치 임베딩(고정 위치 인코딩)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class PositionalEmbedding(layers.Layer): # 입력 시퀀스 길이가 고정되어야 하므로,\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs): # 입력 시퀀스의 최대 길이, 입력 토큰의 차원 수, 출력 임베딩 차원 수\n",
    "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(input_dim=input_dim, output_dim=output_dim) # 입력 토큰 임베딩\n",
    "        self.position_embeddings = layers.Embedding(input_dim=sequence_length, output_dim=output_dim) # 위치 정보 임베딩\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1] # 입력 시퀀스 길이\n",
    "        positions = tf.range(start=0, limit=length, delta=1) # 위치 정보를 나타내는 텐서를 생성\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'output_dim': self.output_dim,\n",
    "            'sequence_length': self.sequence_length,\n",
    "            'input_dim': self.input_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2fc7f16-decf-46c9-a249-f5519d462d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " positional_embedding_1 (Po  (None, None, 256)         5273600   \n",
      " sitionalEmbedding)                                              \n",
      "                                                                 \n",
      " transformer_encoder_3 (Tra  (None, None, 256)         543776    \n",
      " nsformerEncoder)                                                \n",
      "                                                                 \n",
      " global_max_pooling1d_3 (Gl  (None, 256)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5817633 (22.19 MB)\n",
      "Trainable params: 5817633 (22.19 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 20000\n",
    "sequence_length = 600\n",
    "embed_dim = 256\n",
    "num_heads = 2\n",
    "dense_dim = 32\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype='int64')\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(inputs)\n",
    "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2013e5b-a42b-4b42-b5f5-25261863c878",
   "metadata": {},
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint('full_transformer_encoder.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "576bd800-dc12-4bde-b4b0-597da0e30d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2095s 3s/step - loss: 1.3416 - accuracy: 0.5244\n",
      "테스트 정확도 : 0.524\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('full_transformer_encoder.h5',\n",
    "                                custom_objects={'TransformerEncoder':TransformerEncoder,\n",
    "                                               'PositionalEmbedding' : PositionalEmbedding})\n",
    "\n",
    "print(f'테스트 정확도 : {model.evaluate(int_test_ds)[1]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76d55f9-c48f-4eaf-ae9d-0c21b358a812",
   "metadata": {},
   "source": [
    "## BoW 모델 대신 언제 시퀸스 모델을 사용할까?\n",
    "=> 단어의 순서를 무시하고 단어의 빈도만 처리하는 것 대신 단어의 순서를 고려해야 할 때가 언제인지\n",
    "\n",
    "1. 문맥을 고려해야 할 때 : dog bites man, man bites dog\n",
    "2. 언어 모델링 : 다음 단어를 예측하거나 텍스트를 생성할 때\n",
    "3. 긴 의존성 : RNN과 트랜스포머는 긴 시퀸스 내에서 멀리 떨어진 단어 간의 의존성 파악할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32abc3c2-e48c-4cf8-93c7-d454bb405fab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
