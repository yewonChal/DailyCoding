{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5dab264-642b-4b28-9378-337a14521c39",
   "metadata": {},
   "source": [
    "# Attention\n",
    "\n",
    "### seq2seq 한계\n",
    "\n",
    "-> 인코더 : 입력 시퀸스를 받아 고정된 크기의 컨텍스트 벡터로 변환(타임스탭의 마지막 상태를 활용)\n",
    "\n",
    "-> 디코더 : 인코더가 생성한 컨텍스트 벡터를 전달받아 출력 시퀸스를 생성\n",
    "\n",
    "===> 정보 손실 : 입력 시퀸스를 고정된 크기의 컨텍스트 벡터로 변환 ➡️ 압축\n",
    "\n",
    "===> 기울기 소실 : 긴 시퀸스를 처리할 때 초반 부분의 정보를 충분히 학습할 수 없다.\n",
    "\n",
    "#### 어텐션 또한 입력 시퀸스의 모든 타임 스탭을 참조하여 디코더가 출력 시퀸스를 생성할 때, 각 타임스탭의 중요도를 부여하여 긴 시퀸스도 처리할 수 있다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0e854237-3b81-4398-bb1a-02e34961b34a",
   "metadata": {},
   "source": [
    "아이디어 : 모든 단어에 가중치를 부여하여 중요한 단어에 조금 더 집중할 수 있도록 하겠다.\n",
    "\n",
    "1. 컨텍스트 벡터 생성 : 디코더의 각 타임스탭마다 다른 컨텍스트 벡터를 동적 생성한다.(입력 시퀸스의 모든 타임스탭의 은닉 상태를 가중함)\n",
    "2. 가중치 계산 : 입력 시퀸스에 대해 각 타입스탭 별로 가중치를 계산한다.(디코더의 은닉 상태와 인코더의 은닉 상태들 간의 유사도)\n",
    "3. 가중합 : 입력 시퀸스의 각 타임스탭의 은닉 상태에 해당 가중치를 곱하여 새로운 콘텍스트 벡터를 생성한다.\n",
    "4. 출력 : 새롭게 생성된 컨텍스트 벡터와 이전 은닉 상태를 이용하여 다음 단어를 예측\n",
    "\n",
    "입력 시퀸스의 은닉 상태 계산(입력 시퀸스 x1, x2, ..., xn에 대한 각 타임스탭 t에 대한 은닉 상태 h(t)를 계산 -> \n",
    "디코더의 은닉 상태 계산(이전의 출력과 현재의 은닉 상태를 기반으로 다음 은닉 상태 s(t+1)을 계산 -> \n",
    "어텐션 가중치 계산(α(i) = softmax(e(i)) 여기서 e(i) = score(s(t+1), h(i)) 디코더와 인코더의 유사도 점수 -> \n",
    "컨텍스트 벡터 생성(각 은닉상태에 가중치를 곱한다. C(t+1) = ∑(α(i)*h(i)) -> \n",
    "디코더의 출력 계산(새로운 컨텍스트 벡터 C(t+1)과 이전 은닉 상태들을 사용하여 다음 출력을 예측한다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef95bd8e-404a-442e-9e91-c65e93c25d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM\n",
      "Transformer\n"
     ]
    }
   ],
   "source": [
    "dict = {'2024' : 'LSTM', '2025' : 'Transformer'} # {key : value)\n",
    "\n",
    "print(dict['2024'])\n",
    "print(dict['2025'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "11229c03-dad4-4ff4-89af-8a3e34f3d0ad",
   "metadata": {},
   "source": [
    "# Attention(Q, K, V)\n",
    "\n",
    "Q : Query -> t 시점의 디코더 셀의 은닉 상태(현재 점의 디코더 output)\n",
    "K : Key -> 모든 시점의 인코더 셀의 은닉 상태(모든 시점의 인코더 output)\n",
    "V : Value -> 모든 시점의 인코더 셀의 은닉 상태의 유사도(모든 시점의 인코더 output) key의 유사도에 따라 value가 정해진다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "037c982b-bc99-4456-a47a-b7bc337a0ec2",
   "metadata": {},
   "source": [
    "- seq2seq : 번역가가 독일어책을 처음부터 끝까지 읽는다. 그 다음 처음부터 번역을 시작한다.\n",
    "- attention : 번역가가 독일어책을 처음부터 끝까지 읽으면서 핵심 키워드를 따로 적어놓는다. 그 다음 핵심 키워드를 참고하여 번역을 시작한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac247434-6374-4724-af9e-d9cba65cbc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM, Concatenate, Dropout\n",
    "from tensorflow.keras import Input, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32c1906f-8397-4727-93f1-18b7f356d204",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5bb7524-00d0-4422-966c-bca315348a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰의 최대 길이 :  2494\n",
      "리뷰의 평균 길이 :  238.71364\n"
     ]
    }
   ],
   "source": [
    "print('리뷰의 최대 길이 : ', max(len(l) for l in X_train))\n",
    "print('리뷰의 평균 길이 : ', sum(map(len, X_train))/len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c174b6c0-7633-4dab-abb8-67019aec6e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 500\n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9f90007-3a64-4dcc-8040-a2686d1736e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f2b47469-3baf-45b3-b90e-6e4c4b752401",
   "metadata": {},
   "source": [
    "class Attention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(Attention, self).__init__()\n",
    "        self.W1 = Dense(units) # 가중치로 입력 값 변환\n",
    "        self.W2 = Dense(units) # 가중치로 입력 값 변환\n",
    "        self.V = Dense(1) # 스코어를 계산하기 위한 Dense\n",
    "\n",
    "    def call(self, values, query):\n",
    "        # query shape = (batch_size, hidden_size)\n",
    "        hidden_with_time_axis = tf.expend_dims(query, 1) # 이후의 연산을 위한 차원을 변경\n",
    "\n",
    "        # score 계산 : values에 W1, hidden_with_time_axis W2를 적용하고 tanh 활성화 함수를 통과 시킨 후 V를 적용시켜 스코어를 계산\n",
    "        score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "        attention_weights = tf.nn.softmax(score, axis=1) # softmax 함수를 적용하여 스코어를 확률 분포로 변환\n",
    "\n",
    "        context_vector = attention_weights * values # weight과 vaule를 곱하여 컨텐스트 벡터를 계산\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1) # 차원을 기준으로 합하여 최종 context_vector을 계산\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e03655c-870c-4f20-a99b-0d0c3692caa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(Attention, self).__init__()\n",
    "        self.W1 = Dense(units) # 가중치로 입력 값 변환\n",
    "        self.W2 = Dense(units) # 가중치로 입력 값 변환\n",
    "        self.V = Dense(1) # 스코어를 계산하기 위한 Dense\n",
    "\n",
    "    def call(self, values, query):\n",
    "        # query shape = (batch_size, hidden_size)\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1) # 이후의 연산을 위한 차원을 변경\n",
    "\n",
    "        # score 계산 : values에 W1, hidden_with_time_axis W2를 적용하고 tanh 활성화 함수를 통과시킨 후 V 를 적용시켜 스코어를 계산\n",
    "        score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "        attention_weights = tf.nn.softmax(score, axis=1) # softmax 함수를 적용하여 스코어를 확률 분포로 변환\n",
    "\n",
    "        context_vector = attention_weights * values # weights과 values를 곱하여 컨텐스트 벡터를 계산\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1) # 차원을 기준으로 합하여 최종 context_vector를 계산\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e9bff6d8-9faf-4fc1-b571-ef2df61bc329",
   "metadata": {},
   "source": [
    "max_len = 100 \n",
    "vocab_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e9d6a91-cb0b-4e69-9fde-447f18a51d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM, Concatenate, Dropout\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e877921c-6b28-4ba1-add0-5e184fb93197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-16 11:14:33.389310: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-16 11:14:33.390318: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-16 11:14:33.390982: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-07-16 11:14:33.464797: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2024-07-16 11:14:33.486600: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-16 11:14:33.487331: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-16 11:14:33.487972: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "sequence_input = Input(shape=(max_len,), dtype='int32')\n",
    "embedded_sequences = Embedding(vocab_size, 128)(sequence_input)\n",
    "lstm = Bidirectional(LSTM(64, dropout=0.5, return_sequences = True))(embedded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13474fe8-065b-4646-8f4b-b6aeef112698",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-16 11:14:33.600182: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-16 11:14:33.600839: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-16 11:14:33.602090: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-07-16 11:14:33.676661: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2024-07-16 11:14:33.698295: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-16 11:14:33.698953: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-16 11:14:33.699596: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "# 순방향 은닉상태와 셀 상태(forword_h, forword_c), 역방향 은닉상태와 셀상태(backword_h, backword_c)\n",
    "\n",
    "lstm, forward_h, forward_c, backward_h, backward_c = Bidirectional(LSTM(64, dropout=0.5, return_sequences=True, return_state=True))(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4eb2434-b47e-4e95-a9f5-20bba3223737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 500, 128) (None, 64) (None, 64) (None, 64) (None, 64)\n"
     ]
    }
   ],
   "source": [
    "print(lstm.shape, forward_h.shape, forward_c.shape, backward_h.shape, backward_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "85e03720-c813-4bf9-88ef-c470df99b4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_h = Concatenate()([forward_h, backward_h])\n",
    "state_c = Concatenate()([forward_c, backward_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a5949a28-1812-4140-a4ce-8c6c24113a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ccae2e15-618f-48a3-b588-50aab479ca60",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = Attention(64)\n",
    "context_vector, attention_weights = attention(lstm, state_h)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aea44e0d-e3ab-4535-8c3e-1b753c75fbd0",
   "metadata": {},
   "source": [
    "dense1 = Dense(20, activation='relu')(context_vector)\n",
    "dropout = Dropout(0.5)(dense1)\n",
    "output = Dense(1, activation='sigmoid')(dropout)\n",
    "model = Model(inputs=sequence_input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "762258d4-c48e-486a-895e-86330ca48f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense1 = Dense(20, activation='relu')(context_vector)\n",
    "dropout = Dropout(0.5)(dense1)\n",
    "output = Dense(1, activation='sigmoid')(dropout)\n",
    "model = Model(inputs=sequence_input, outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b38f063-7522-4ab2-b739-ea90a0155471",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3544d744-bb40-4bc9-bbf5-5afd6863037e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 500)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 500, 128)     1280000     ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirectional  (None, 500, 128)    98816       ['embedding_1[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_3 (Bidirectional  [(None, 500, 128),  98816       ['bidirectional_2[0][0]']        \n",
      " )                               (None, 64),                                                      \n",
      "                                 (None, 64),                                                      \n",
      "                                 (None, 64),                                                      \n",
      "                                 (None, 64)]                                                      \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 128)          0           ['bidirectional_3[0][1]',        \n",
      "                                                                  'bidirectional_3[0][3]']        \n",
      "                                                                                                  \n",
      " attention_1 (Attention)        ((None, 128),        16577       ['bidirectional_3[0][0]',        \n",
      "                                 (None, 500, 1))                  'concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 20)           2580        ['attention_1[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 20)           0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            21          ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,496,810\n",
      "Trainable params: 1,496,810\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cf676718-0db2-4bee-a2f3-ad22ff9a7df6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-16 11:14:35.454463: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-16 11:14:35.455366: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-16 11:14:35.455963: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-07-16 11:14:35.539243: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2024-07-16 11:14:35.562976: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-16 11:14:35.563627: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-16 11:14:35.564223: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-07-16 11:14:35.670736: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-16 11:14:35.671639: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-16 11:14:35.673335: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-07-16 11:14:35.758309: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2024-07-16 11:14:35.781912: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-16 11:14:35.782609: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-16 11:14:35.783200: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-07-16 11:14:36.094105: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2024-07-16 11:14:36.317139: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2024-07-16 11:14:36.532703: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-16 11:14:36.533603: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-16 11:14:36.534228: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-07-16 11:14:36.620419: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2024-07-16 11:14:36.645642: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-16 11:14:36.646363: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-16 11:14:36.646993: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-07-16 11:14:36.754092: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-16 11:14:36.755159: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-16 11:14:36.755822: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-07-16 11:14:36.842160: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2024-07-16 11:14:36.865670: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-16 11:14:36.866412: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-16 11:14:36.867038: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-07-16 11:14:37.176902: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2024-07-16 11:14:37.400741: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - ETA: 0s - loss: 0.5460 - accuracy: 0.6919"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-16 11:25:05.895845: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-16 11:25:05.897046: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-16 11:25:05.897710: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-07-16 11:25:06.169566: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2024-07-16 11:25:06.192658: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-16 11:25:06.193424: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-16 11:25:06.194022: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-07-16 11:25:06.298659: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-16 11:25:06.299539: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-16 11:25:06.300283: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-07-16 11:25:06.388612: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2024-07-16 11:25:06.415824: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-16 11:25:06.416620: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-16 11:25:06.417376: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 810s 8s/step - loss: 0.5460 - accuracy: 0.6919 - val_loss: 0.3101 - val_accuracy: 0.8660\n",
      "Epoch 2/3\n",
      "98/98 [==============================] - 740s 8s/step - loss: 0.3028 - accuracy: 0.8878 - val_loss: 0.2885 - val_accuracy: 0.8831\n",
      "Epoch 3/3\n",
      "98/98 [==============================] - 729s 7s/step - loss: 0.2155 - accuracy: 0.9255 - val_loss: 0.3183 - val_accuracy: 0.8784\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=3, batch_size=256, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "34dd6e6f-fccd-4fc1-8a01-750bdc082623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 162s 207ms/step - loss: 0.3183 - accuracy: 0.8784\n",
      "Test Acc : 0.8784000277519226\n"
     ]
    }
   ],
   "source": [
    "print('Test Acc :', model.evaluate(X_test, y_test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b2ee95a-1e20-4ac4-b0df-32c33391130b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.layers import Layer\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60349cfd-ccd0-4961-aa1f-0703963a73ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagdangu Attention(바다나우 어텐션) : Query가 t 시점이 아닌 t-1 시점의 디코더 셀의 은닉상태\n",
    "class AttentionLayer(Layer):\n",
    "    # 생성자 : 부모클래스 Layer를 호출하여 초기화(build 메서드에서 설정을 수행하므로 생성자에서 작업을 하지 않는다.)\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    # build : 클래스가 처음 사용될 때 한 번 호출되는 메서드\n",
    "    def buile(self, input_shape):\n",
    "        # assert문은 특정 조건이 참인지 아닌지 검증(거짓이면 오류 발생)\n",
    "        assert isinstance(input_shape, list) # input_shape이 list 타입인지?\n",
    "\n",
    "        # 가중치 W_a, U_a, V_a를 초기화한다.\n",
    "        # W_a : 인코더 출력에 대한 가중치 행렬\n",
    "        # U_a : 디코더 히든 상태에 대한 가중치 행렬\n",
    "        # V_a : attention score를 계산하기 위한 가중치 벡터\n",
    "        self.W_a = self.add_weight(name='W_a', shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])), initializer='uniform', trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a', shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])), initializer='uniform', trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a', shape=tf.TensorShape((input_shape[0][2], 1)), initializer='uniform', trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape) # 부모클래스의 build 메서드 호출\n",
    "\n",
    "    def call(self, inputs, verbose=False):\n",
    "        assert type(inputs) == list # input이 list 타입인지?\n",
    "\n",
    "        # 인코더와 디코더 출력 시퀸스 저장(inputs에는 인코더와 디코더의 출력을 갖고 있다.)\n",
    "        encoder_out_seq, decoder_out_seq = inputs \n",
    "        if verbose: # 지워주어도 상관 없는 부분\n",
    "            print(encoder_out_seq.shape)\n",
    "            print(decoder_out_seq.shape)\n",
    "\n",
    "        # 단일 디코더 계산 \n",
    "        def energy_step(inputs, states):\n",
    "            # inputs : batch_size * 1 * de_in_dim(현재 디코더 상태)\n",
    "            # states : batch_size * 1 * de_latent_dim(전체 상태)\n",
    "            \n",
    "            assert_msg = 'States must be an iterable. Got {} of type {}'.format(states, type(states))\n",
    "            assert isinstance(states, list) or instance(states, tuple), assert_msg\n",
    "\n",
    "            # 텐서를 형성하는데 필요한 매개변수\n",
    "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
    "            de_hidden = inputs.shape[-1]\n",
    "\n",
    "            # W(a) * s : s(인코더 출력)\n",
    "            W_a_dot_s = K.dot(decoder_out_seq, self.W_a)\n",
    "\n",
    "            # U(a) * h(j) : h(j)(현재 디코더 상태)\n",
    "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)\n",
    "\n",
    "            if verbose:\n",
    "                print(U_a_dot_h.shape)\n",
    "\n",
    "            # 두 결과의 합에 tanh 함수 적용\n",
    "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
    "\n",
    "            if verbose:\n",
    "                print(Ws_plus_Uh.shape)\n",
    "\n",
    "            # 배치크기 세팅 softmax를 이용하여 attention score를 계산\n",
    "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=1)\n",
    "            e_i = K.softmax(e_i)\n",
    "\n",
    "            if verbose:\n",
    "                print(e_i.shape)\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        # Attention score(e_i)를 사용하여 컨텍스트 벡터(c(i)) 생성(계산)\n",
    "        def context_step(inputs, states):\n",
    "            assert_msg = 'States must be an iterable. Got {} of type {}'.format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            # attention score를 가중치로 사용하여 인코더 출력의 가중합을 계산해 컨텍스트 벡터를 만든다.\n",
    "            c_i = K.sum(encoder_out_seq * K.expand_dums(inputs, -1), axis=1)\n",
    "            if verbose:\n",
    "                print(c_i.shape)\n",
    "                \n",
    "            return c_i, [c_i]\n",
    "\n",
    "        # 가짜 상태 : K.rnn 함수를 초기화하기 위해 사용\n",
    "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
    "        fake_state_e = K.sum(encodre_out_seq, axis=2)\n",
    "\n",
    "        # energy_step을 통해 attention score를 계산(rnn을 사용하여 디코더 시퀸스를 반복하여 각 타임스탭에 대한 점수)\n",
    "        last_out, e_outputs, _ = K.rnn(energy_step, decoder_out_seq, [fake_state_e],)\n",
    "\n",
    "        # 계산된 attention score를 통해 컨텍스트 벡터를 계산한다.\n",
    "        last_out, c_outputs, _ = K.rnn(context_step, e_outputs, [fake_state_c], )\n",
    "\n",
    "        # c_outputs : 각 디코더 타임스탭에 대한 컨텍스트 벡터, e_outputs : 각 디코더 타임스탭에 대한 attention score\n",
    "        return c_outputs, e_outputs\n",
    "\n",
    "    # 레이어의 출력형태를 정의하는 메서드\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])), # 컨텍스트 벡터의 형태\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1])) # attention score 형태\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5108dec-f207-407f-9c8e-0a552807dc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open('movie_lines.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n",
    "\n",
    "convers = open('movie_conversations.txt', encoding='utf-8', errors='ignore').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7214c45-cfc6-4a5c-b284-3a5cf6f2985e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304714, 83098)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines), len(convers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da48d332-63ea-4cb5-ba22-db881c84ca2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b2fb6e7-609e-4a93-84fc-57f7980e360f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['L194', 'L195', 'L196', 'L197'],\n",
       " ['L198', 'L199'],\n",
       " ['L200', 'L201', 'L202', 'L203']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exchn = []\n",
    "for conver in convers:\n",
    "    exchn.append(conver.split(' +++$+++ ')[-1][1:-1].replace(\"'\", \" \").replace(\",\", \"\").split())\n",
    "\n",
    "exchn[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8251f10c-22ba-4eff-abf6-71ce90b593ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag = {}\n",
    "for line in lines:\n",
    "    # print(line.split(' +++$+++ ')[0])\n",
    "    # print(line.split(' +++$+++ ')[-1])\n",
    "    diag[line.split(' +++$+++ ')[0]] = line.split(' +++$+++ ')[-1]\n",
    "\n",
    "# print(diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dac594c2-85c7-41e7-a074-b5070f6d96cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(lines, convers, conver, line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddf92f8a-2b84-4d8b-9fc0-1cd3890b9c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "answers = []\n",
    "\n",
    "for conver in exchn:\n",
    "    for i in range(len(conver)-1):\n",
    "        questions.append(diag[conver[i]])\n",
    "        answers.append(diag[conver[i+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a3ee6ae-cb0e-47ea-8673-b7b8a3d54f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.',\n",
       "  \"Well, I thought we'd start with pronunciation, if that's okay with you.\",\n",
       "  'Not the hacking and gagging and spitting part.  Please.'],\n",
       " [\"Well, I thought we'd start with pronunciation, if that's okay with you.\",\n",
       "  'Not the hacking and gagging and spitting part.  Please.',\n",
       "  \"Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\"])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[:3], answers[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6498dbcb-b73f-4b01-8976-14725df87152",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(diag, exchn, conver, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51220c4e-7c75-44eb-ab90-4490c45c190c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ques = []\n",
    "sorted_ans = []\n",
    "\n",
    "for i in range(len(questions)):\n",
    "    if len(questions[i]) < 13:\n",
    "        sorted_ques.append(questions[i])\n",
    "        sorted_ans.append(answers[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "720fb1cb-c97e-4caa-ad2a-0604b4bb6cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(txt):\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(r\"i'm'\", \"i am\", txt)\n",
    "    txt = re.sub(r\"he's\", \"he is\", txt)\n",
    "    txt = re.sub(r\"she's\", \"she is\", txt)\n",
    "    txt = re.sub(r\"that's\", \"that is\", txt)\n",
    "    txt = re.sub(r\"what's\", \"what is\", txt)\n",
    "    txt = re.sub(r\"where's\", \"where is\", txt)\n",
    "    txt = re.sub(r\"\\'ll\", \"will\", txt)\n",
    "    txt = re.sub(r\"\\'re\", \"are\", txt)\n",
    "    txt = re.sub(r\"\\'d\", \"would\", txt)\n",
    "    txt = re.sub(r\"won't\", \"will not\", txt)\n",
    "    txt = re.sub(r\"can't\", \"can not\", txt)\n",
    "    txt = re.sub(r\"[^\\w\\s]\", \"\", txt) # 숫자, 문자, 언더바(\\n), 공백(\\s)을 제외하고 모두 제거\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ff62ded-6eb1-470a-bca2-dc933083181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_ques = []\n",
    "clean_ans = []\n",
    "\n",
    "for line in sorted_ques:\n",
    "    clean_ques.append(clean_text(line))\n",
    "\n",
    "for line in sorted_ans:\n",
    "    clean_ans.append(clean_text(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffdf135e-7262-4821-8a9e-d3f9f06c1f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['cameron', 'why', 'there'],\n",
       " ['the thing is cameron  im at the mercy of a particularly hideous breed of loser  my sister  i can not date until she does',\n",
       "  'unsolved mystery  she used to be really popular when she started high school then it was just like she got sick of it or something',\n",
       "  'where'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_ques[:3], clean_ans[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c4a4bf8-0726-49b5-9331-b547683d9c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(answers, questions, line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78ae6829-3807-4553-bf5a-81ddc952fe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(sorted_ans, sorted_ques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4dfa2b6-81fe-4431-b89b-e62cbf0ef917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the thing is cameron  im at the mercy of a particularly hideous breed of loser  my sister  i can not date until she does',\n",
       " 'unsolved mystery  she used to be really popular when she started high school then it was just like she got sick of it or something',\n",
       " 'where']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_ans[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "389cae0d-c825-484f-bb45-a33c12dd55f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(clean_ans)):\n",
    "    clean_ans[i] = ' '.join(clean_ans[i].split()[:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78659cb0-108f-4d52-b324-ee738ffc73ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the thing is cameron im at the mercy of a particularly',\n",
       " 'unsolved mystery she used to be really popular when she started',\n",
       " 'where']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_ans[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23f1f46c-bc86-4389-b4bb-8c23e2bc7d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_ans = clean_ans[:30000]\n",
    "clean_ques = clean_ques[:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2fe3f73-67f0-45ec-b098-c7bbe25e7721",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_total = clean_ans + clean_ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e7148af-1994-4d4a-920e-883042792021",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2count = {}\n",
    "\n",
    "for line in clean_total:\n",
    "    words = line.split()\n",
    "    for word in words:\n",
    "        if word in word2count:\n",
    "            word2count[word] += 1\n",
    "        else:\n",
    "            word2count[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "012dded9-5211-42b2-a836-52b6e3d16ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(word2count['dog'])\n",
    "print(word2count['cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ab499bb-4f5c-4b67-8875-cc38edfc8290",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(word2count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f7b6e55-c75c-4c40-bdaf-492816cefbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(word, line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b596e47-bf06-487e-b723-f5da6d551897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빈도수 낮은 단어 삭제\n",
    "thresh = 5\n",
    "\n",
    "vocab = {}\n",
    "word_num = 0\n",
    "\n",
    "for word, count in word2count.items():\n",
    "    if count >= thresh:\n",
    "        vocab[word] = word_num\n",
    "        word_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ab4de54-4b65-4306-8b38-007d404017d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(380, 1565, 3076)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['dog'], vocab['cat'], word_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ecc5347-0367-4bf4-b8da-984d83cc2f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(word2count, word, count, thresh, word_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ef3b674-8b5e-4ea9-91d6-b2d86134b9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(clean_ans)):\n",
    "    clean_ans[i] = '<SOS> ' + clean_ans[i] + ' <EOS>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "522f8226-7b52-4b26-b442-b17d40015933",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['<PAD>', '<EOS>', '<OUT>', '<SOS>']\n",
    "# 토큰 뒷 부분에 하나씩 삽입\n",
    "x = len(vocab)\n",
    "for token in tokens:\n",
    "    vocab[token] = x\n",
    "    x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab8d3262-7dbb-4c86-801f-c6e1013bf1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3076\n",
      "3077\n",
      "3078\n",
      "3079\n"
     ]
    }
   ],
   "source": [
    "for token in tokens:\n",
    "    print(vocab[token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b4c354a-36a9-4017-b44c-59a066c3c700",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab['cameron'] = vocab['<PAD>']\n",
    "vocab['<PAD>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f84273b1-08f7-4241-bae4-c6ca05224720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3076 0\n"
     ]
    }
   ],
   "source": [
    "print(vocab['cameron'], vocab['<PAD>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "56b0c2bc-9d57-40a8-b376-f2396cff74c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(token, tokens, x, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "59b4cc4b-d8c4-4c04-b4f5-836e7d6d56f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_vocab = {w:v for v, w in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6665ef72-5b7b-4649-ad7c-7817720f0c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PAD> nix\n"
     ]
    }
   ],
   "source": [
    "print(inv_vocab[0], inv_vocab[3023])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "428e6d50-e730-41ec-ae93-f6f8dfeeecf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inp = []\n",
    "for line in clean_ques:\n",
    "    lst = []\n",
    "    for word in line.split():\n",
    "        if word not in vocab:\n",
    "            lst.append(vocab['<OUT>'])\n",
    "        else:\n",
    "            lst.append(vocab[word])\n",
    "\n",
    "    encoder_inp.append(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d9f4fa4e-cbcf-4395-988b-fdc7c7dbdfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inp = []\n",
    "for line in clean_ans:\n",
    "    lst = []\n",
    "    for word in line.split():\n",
    "        if word not in vocab:\n",
    "            lst.append(vocab['<OUT>'])\n",
    "        else:\n",
    "            lst.append(vocab[word])\n",
    "    decoder_inp.append(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f35f102-2e51-45e7-8697-976562d66e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3076], [170], [246]] [[3079, 0, 1, 2, 3076, 4, 5, 0, 3078, 6, 7, 8, 3077], [3079, 3078, 9, 10, 11, 12, 13, 14, 15, 16, 10, 17, 3077], [3079, 18, 3077]]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_inp[:3], decoder_inp[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c8887288-b8f7-480d-8657-59b82493e72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(clean_ans, clean_ques, line, lst, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "521ff621-8d9e-4958-8e3a-141a4f3f7ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "encoder_inp = pad_sequences(encoder_inp, 13, padding='post', truncating='post')\n",
    "decoder_inp = pad_sequences(decoder_inp, 13, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "abbcff0d-b2e4-4665-ba79-d3ef0d795ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_final_output = []\n",
    "for i in decoder_inp:\n",
    "    decoder_final_output.append(i[1:])\n",
    "\n",
    "decoder_final_output = pad_sequences(decoder_final_output, 13, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eedf0407-c813-4f2d-ba2c-5135b27d23d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 13) (30000, 13) (30000, 13)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_inp.shape, decoder_inp.shape, decoder_final_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "330944f0-42b4-4ba2-8a45-7982602115e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a58d6219-d490-4829-84df-d0d74b6c8a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(vocab)\n",
    "MAX_LEN = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2329cc31-dc23-45bb-a424-bb2787f54804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'be'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_vocab[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8a4af80a-5561-4d52-9a72-5c3828a40313",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "decoder_final_output = to_categorical(decoder_final_output, VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3d15afdf-2416-4645-91f3-da844a081a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 13, 3080)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_final_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1bd11021-5ece-450d-89a8-3cbc059023a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "\n",
    "with open('glove.6B.50d.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f41566f2-d88c-472e-ac7d-470158faa1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimention = 50\n",
    "\n",
    "def embedding_matrix_creater(embedding_dimention, word_index):\n",
    "    embedding_matrix = np.zeros((len(word_index)+1, embedding_dimention))\n",
    "\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    return embedding_matrix\n",
    "\n",
    "embedding_matrix = embedding_matrix_creater(embedding_dimention, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "76cdf071-3f8b-4d74-9cc6-399f954ab9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5e8f05fb-eeab-4ff0-a570-96d5365a1c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3081, 50)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c35a8384-4bc0-4b53-bc95-ec35bc390f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.11019981e-01, -2.28719994e-01,  2.07699999e-01, -2.02370003e-01,\n",
       "        5.06969988e-01, -5.78930005e-02, -4.17290002e-01, -7.53410012e-02,\n",
       "       -3.04540008e-01, -3.28600011e-03,  4.44810003e-01,  4.18179989e-01,\n",
       "       -3.34089994e-01,  3.29170004e-02,  9.88720000e-01,  9.19839978e-01,\n",
       "        4.05209988e-01,  1.92499999e-02, -1.05200000e-01, -7.98650026e-01,\n",
       "       -3.64030004e-01, -8.79950002e-02,  7.21819997e-01,  1.11139998e-01,\n",
       "        2.15299994e-01, -1.94110000e+00, -2.63760000e-01,  4.45499986e-01,\n",
       "        2.75860012e-01, -2.11040005e-01,  4.02120018e+00, -6.19429983e-02,\n",
       "       -3.21339995e-01, -8.19220006e-01,  2.10800007e-01, -2.04139993e-01,\n",
       "        7.26249993e-01,  4.75169986e-01, -3.98530006e-01, -3.91680002e-01,\n",
       "       -3.45809996e-01,  2.59280000e-02,  1.30720004e-01,  7.35620022e-01,\n",
       "       -1.51989996e-01, -1.84389994e-01, -6.71280026e-01,  1.66920006e-01,\n",
       "       -5.00629991e-02,  1.92410007e-01])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2ca8087f-4352-4f71-b877-2159ac4d9b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Input, Bidirectional, Concatenate, Dropout, Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "79e2307d-5480-4a71-be3e-0ce7e793037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = Embedding(VOCAB_SIZE+1, embedding_dimention, trainable=True)\n",
    "\n",
    "embed.build((None,)) # 임베딩 레이어의 입력크기를 설정 (None,) : 크기가 가변적\n",
    "embed.set_weights([embedding_matrix]) # 가중치 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "45bdd919-61a2-467e-8b3e-5be6eb25c376",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 09:13:28.401222: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-17 09:13:28.402519: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-17 09:13:28.403241: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-07-17 09:13:28.490896: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2024-07-17 09:13:28.516823: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-17 09:13:28.517785: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-17 09:13:28.518540: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "enc_inp = Input(shape=(MAX_LEN, ))\n",
    "\n",
    "enc_embed = embed(enc_inp)\n",
    "enc_lstm = Bidirectional(LSTM(512, return_state=True, dropout=0.1, return_sequences=True))\n",
    "\n",
    "encoder_outputs, forward_h, forward_c, backward_h, backward_c = enc_lstm(enc_embed)\n",
    "\n",
    "state_h = Concatenate()([forward_h, backward_h])\n",
    "state_c = Concatenate()([forward_c, backward_c])\n",
    "\n",
    "enc_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a6cee851-af1f-41f2-a629-db85d2a45390",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 09:13:29.764986: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-07-17 09:13:29.766056: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-07-17 09:13:29.766776: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "dec_inp = Input(shape=(MAX_LEN, ))\n",
    "\n",
    "dec_embed = embed(dec_inp)\n",
    "dec_lstm = LSTM(1024, return_state=True, dropout=0.1, return_sequences=True)\n",
    "output, _, _ = dec_lstm(dec_embed, initial_state=enc_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "932502ed-adfa-468d-84ed-83f7210f14c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "Exception encountered when calling layer \"attention_layer\" (type AttentionLayer).\n\nin user code:\n\n    File \"/var/folders/mr/zpw8mcz14pj_gkyqs4k_zl4c0000gn/T/ipykernel_8881/2801044672.py\", line 81, in call  *\n        fake_state_e = K.sum(encodre_out_seq, axis=2)\n\n    NameError: name 'encodre_out_seq' is not defined\n\n\nCall arguments received by layer \"attention_layer\" (type AttentionLayer):\n  • inputs=['tf.Tensor(shape=(None, 13, 1024), dtype=float32)', 'tf.Tensor(shape=(None, 13, 1024), dtype=float32)']\n  • verbose=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Attention\n\u001b[1;32m      2\u001b[0m attn_layer \u001b[38;5;241m=\u001b[39m AttentionLayer()\n\u001b[0;32m----> 3\u001b[0m attn_op, attn_state \u001b[38;5;241m=\u001b[39m \u001b[43mattn_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 컨텍스트 벡터, attention score\u001b[39;00m\n\u001b[1;32m      4\u001b[0m decoder_concat_input \u001b[38;5;241m=\u001b[39m Concatenate(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)([output, attn_op])\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/mr/zpw8mcz14pj_gkyqs4k_zl4c0000gn/T/__autograph_generated_file3d1q5v07.py:117\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, inputs, verbose)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fscope_2\u001b[38;5;241m.\u001b[39mret(retval__2, do_return_2)\n\u001b[1;32m    116\u001b[0m fake_state_c \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(K)\u001b[38;5;241m.\u001b[39msum, (ag__\u001b[38;5;241m.\u001b[39mld(encoder_out_seq),), \u001b[38;5;28mdict\u001b[39m(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), fscope)\n\u001b[0;32m--> 117\u001b[0m fake_state_e \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(K)\u001b[38;5;241m.\u001b[39msum, (ag__\u001b[38;5;241m.\u001b[39mld(encodre_out_seq),), \u001b[38;5;28mdict\u001b[39m(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m), fscope)\n\u001b[1;32m    118\u001b[0m (last_out, e_outputs, _) \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(K)\u001b[38;5;241m.\u001b[39mrnn, (ag__\u001b[38;5;241m.\u001b[39mld(energy_step), ag__\u001b[38;5;241m.\u001b[39mld(decoder_out_seq), [ag__\u001b[38;5;241m.\u001b[39mld(fake_state_e)]), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m    119\u001b[0m (last_out, c_outputs, _) \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(K)\u001b[38;5;241m.\u001b[39mrnn, (ag__\u001b[38;5;241m.\u001b[39mld(context_step), ag__\u001b[38;5;241m.\u001b[39mld(e_outputs), [ag__\u001b[38;5;241m.\u001b[39mld(fake_state_c)]), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "\u001b[0;31mNameError\u001b[0m: Exception encountered when calling layer \"attention_layer\" (type AttentionLayer).\n\nin user code:\n\n    File \"/var/folders/mr/zpw8mcz14pj_gkyqs4k_zl4c0000gn/T/ipykernel_8881/2801044672.py\", line 81, in call  *\n        fake_state_e = K.sum(encodre_out_seq, axis=2)\n\n    NameError: name 'encodre_out_seq' is not defined\n\n\nCall arguments received by layer \"attention_layer\" (type AttentionLayer):\n  • inputs=['tf.Tensor(shape=(None, 13, 1024), dtype=float32)', 'tf.Tensor(shape=(None, 13, 1024), dtype=float32)']\n  • verbose=False"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Attention\n",
    "attn_layer = AttentionLayer()\n",
    "attn_op, attn_state = attn_layer([encoder_outputs, output]) # 컨텍스트 벡터, attention score\n",
    "decoder_concat_input = Concatenate(axis=-1)([output, attn_op])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c300d5-fd5e-4568-9d8b-9a9ffb94c160",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_dense = Dense(VOCAB_SIZE, activation = 'softmax')\n",
    "final_output = dec_dense(decoder_concat_input)\n",
    "\n",
    "model = Model([enc_inp, dec_inp], final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83eed20-5f83-4ec2-904a-2f2cbc12c7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2504c3-2fee-49a2-ad9e-e134fc89dcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0ae2cb-732a-4316-abfe-6f7395137027",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df68e197-011e-444a-a355-c88b06d2b9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([encoder_inp, decoder_inp], decoder_final_output, epochs=10, batch_size=64, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c39bfde-cffd-4b3e-9754-6701c3e3279e",
   "metadata": {},
   "source": [
    "model.save('chatbot.keras')\n",
    "model.save_weights('chatbot.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4db36cb-73ff-44f2-bf00-84f5500fe62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_model = tf.keras.models.Model(enc_inp, [encoder_outputs, enc_states])\n",
    "\n",
    "decoder_state_input_h = tf.keras.layers.Input(shape=(1024, ))\n",
    "decoder_state_input_c = tf.keras.layers.Input(shape=(1024, ))\n",
    "\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs, state_h, state_c = dec_lstm(dec_embed, initial_state=decoder_states_inputs)\n",
    "\n",
    "decoder_states = [state_h, state_c]\n",
    "\n",
    "dec_model = tf.keras.models.Model([dec_inp, decoder_states_inputs], [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4d2ada-ffe5-4d33-a733-08f07ce662d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('#'*30)\n",
    "print('#       Start Chatting       #')\n",
    "print('#'*30)\n",
    "\n",
    "prepro1 = ''\n",
    "\n",
    "while prepro1 != 'q' : # q를 입력하면 프로그램 종료\n",
    "    prepro1 = input('you : ')\n",
    "    try :\n",
    "        prepro1 = clean_text(prepro1) # 입력문장에 대한 전처리\n",
    "        prepro = [prepro1]\n",
    "\n",
    "        txt = []\n",
    "        for x in prepro: # 토큰화\n",
    "            lst = []\n",
    "            for y in x.split():\n",
    "                try:\n",
    "                    lst.append(vocab[y]) # 정수\n",
    "                except:\n",
    "                    lst.append(vocab['<OUT>']) # 없으면 <OUT> 토큰 입력\n",
    "            txt.append(lst)\n",
    "        txt = pad_sequences(txt, MAX_LEN, padding='post') # 패딩\n",
    "\n",
    "        enc_op, stat = enc_model.predict(txt) # 인코더 모델로 출력을 생성 (출력 시퀸스, 상태)\n",
    "        empty_target_seq = np.zeros((1,1)) # 초기 디코더 입력 시퀸스 초기화\n",
    "        empty_target_seq[0,0] = vocab['<SOS>']\n",
    "        stop_condition = False\n",
    "        decoded_translation = ''\n",
    "\n",
    "        while not stop_condition :\n",
    "            dec_outputs, h, c = dec_model.predict([empty_target_seq] + stat) # 디코더 모델로 출력 생성\n",
    "\n",
    "            attn_op, attn_state = attn_layer([enc_op, dec_outputs]) # attention layer를 사용하여 컨텍스트 벡터, 가중치 반환\n",
    "            decoder_concat_input = Concatenate(axis=-1)([dec_outputs, attn_op])\n",
    "            decoder_concat_input = dec_dense(decoder_concat_input) # 디코더 모델 출력 시퀸스와 컨텍스트 벡터를 denselayer로 변환\n",
    "\n",
    "            sampled_word_index = np.argmax(decoder_concat_input[0,-1,:]) # 가장 높은 확률을 가진 단어를 가져온다.\n",
    "            sampled_word = inv_vocab[sampled_word_index] + ' '\n",
    "\n",
    "            if sampled_word != '<EOS> ':\n",
    "                decoded_translation += sampled_word\n",
    "\n",
    "            if sampled_word == '<EOS> ' or len(decoded_translation.split()) > MAX_LEN:\n",
    "                stop_condition = True\n",
    "\n",
    "            # 다음 입력 준비\n",
    "            empty_target_seq = np.zeros((1,1))\n",
    "            empty_target_seq[0,0] = sampled_word_index\n",
    "            stat = [h,c]\n",
    "\n",
    "        print('chatbot :', decoded_translation)\n",
    "        print('='*30)\n",
    "\n",
    "    except:\n",
    "        print('Please try again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db516c0c-2ffe-487c-9b09-c93505d1d7ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a80dbe2-be32-4ae9-8de9-3117c42918e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
